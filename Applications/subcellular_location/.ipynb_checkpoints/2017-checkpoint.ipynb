{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetFile='2017/S1_dataset/5939pdataset/idLocation.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDatasetFile='2017/S1_dataset/920pdataset/test_idLocation_code.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset=pd.read_csv(testDatasetFile,sep='|',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P00505</td>\n",
       "      <td>1 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9NP58</td>\n",
       "      <td>1 3 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q96HD9</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O43687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q8N7J2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1\n",
       "0  P00505    1 4 \n",
       "1  Q9NP58  1 3 4 \n",
       "2  Q96HD9    1 2 \n",
       "3  O43687      1 \n",
       "4  Q8N7J2      1 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset=pd.read_csv(trainDatasetFile,sep='|',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O95866</td>\n",
       "      <td>Cell_membrane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q70Z44</td>\n",
       "      <td>Cell_membrane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q5I7T1</td>\n",
       "      <td>Cell_membrane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O14514</td>\n",
       "      <td>Cell_membrane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q9H159</td>\n",
       "      <td>Cell_membrane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0               1\n",
       "0  O95866  Cell_membrane \n",
       "1  Q70Z44  Cell_membrane \n",
       "2  Q5I7T1  Cell_membrane \n",
       "3  O14514  Cell_membrane \n",
       "4  Q9H159  Cell_membrane "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre process lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLables=trainDataset[[1]]\n",
    "multiplexProteinsIndicesTrain=[]\n",
    "trainLablesOneHot=np.zeros(shape=(trainLables.shape[0],6))\n",
    "\n",
    "lableDict={'Cell_membrane':0,'Cytoplasm':1,'ER_Golgi':2,'Mitochondrion':3,'Nucleus':4,'Secreted':5}\n",
    "\n",
    "for i,row in trainLables.iterrows():\n",
    "    lables=row.str.split(' ')\n",
    "    lables=list(lables)\n",
    "    lables=lables[0]\n",
    "    lables=lables[:-1]\n",
    "    if len(lables)> 1:\n",
    "        multiplexProteinsIndicesTrain.append(i)\n",
    "    for lable in lables:\n",
    "        trainLablesOneHot[i,lableDict[lable]]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5939, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLablesOneHot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate multilex proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplexProteinsIndicesTrain=np.array(multiplexProteinsIndicesTrain)\n",
    "\n",
    "trainLablesOneHotMultiplex=trainLablesOneHot[multiplexProteinsIndicesTrain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLables=testDataset[[1]]\n",
    "multiplexProteinsIndices=[]\n",
    "testLablesOneHot=np.zeros(shape=(testLables.shape[0],6))\n",
    "\n",
    "\n",
    "for i,row in testLables.iterrows():\n",
    "    lables=row.str.split(' ')\n",
    "    lables=list(lables)\n",
    "    lables=lables[0]\n",
    "    lables=lables[:-1]\n",
    "    if len(lables)> 1:\n",
    "        multiplexProteinsIndices.append(i)\n",
    "    for lable in lables:\n",
    "        testLablesOneHot[i,int(lable)-1]=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate multilex proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplexProteinsIndices=np.array(multiplexProteinsIndices)\n",
    "\n",
    "testLablesOneHotMultiplex=testLablesOneHot[multiplexProteinsIndices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data for ven diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data=np.concatenate((trainLablesOneHot,testLablesOneHot))\n",
    "\n",
    "# trainLablesOneHot.shape\n",
    "\n",
    "# all_data.shape\n",
    "\n",
    "# trainLablesOneHot.shape\n",
    "\n",
    "# len(trainLablesOneHot)\n",
    "\n",
    "# [trainLablesOneHot[:,0]==1.0]\n",
    "\n",
    "# Cell_membrane=pd.DataFrame (np.nonzero([all_data[:,0]==1.0])[1])\n",
    "\n",
    "# Cell_membrane.to_csv('ven_chart_files/Cell_membraneIDS.csv',index=False,header=False)\n",
    "\n",
    "# Cytoplasm=pd.DataFrame (np.nonzero([all_data[:,1]==1.0])[1])\n",
    "\n",
    "# Cytoplasm.to_csv('ven_chart_files/CytoplasmIDS.csv',index=False,header=False)\n",
    "\n",
    "# ER_Golgi=pd.DataFrame (np.nonzero([all_data[:,2]==1.0])[1])\n",
    "\n",
    "# ER_Golgi.to_csv('ven_chart_files/ER_Golgi.csv',index=False,header=False)\n",
    "\n",
    "# Mitochondrion=pd.DataFrame (np.nonzero([all_data[:,3]==1.0])[1])\n",
    "\n",
    "# Mitochondrion.to_csv('ven_chart_files/Mitochondrion.csv',index=False,header=False)\n",
    "\n",
    "# Nucleus=pd.DataFrame (np.nonzero([all_data[:,4]==1.0])[1])\n",
    "\n",
    "# Nucleus.to_csv('ven_chart_files/Nucleus.csv',index=False,header=False)\n",
    "\n",
    "# Secreted=pd.DataFrame (np.nonzero([all_data[:,5]==1.0])[1])\n",
    "\n",
    "# Secreted.to_csv('ven_chart_files/Secreted.csv',index=False,header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map uniprot to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain=trainDataset[[0]]\n",
    "\n",
    "dfTrain.columns=['uniprot_ac']\n",
    "\n",
    "#mapString2Uniprot=pd.read_csv('../uniprot2string.tsv',sep='\\t',skiprows=1,usecols=[1,2])\n",
    "mapString2Uniprot=pd.read_csv('../data/all_organisms.uniprot_2_string.2018.tsv',sep='\\t',skiprows=1,usecols=[1,2])\n",
    "\n",
    "\n",
    "#mapString2Uniprot.columns=['species', 'uniprot_ac_uniprot_id', 'string_id', 'identity' ,'bit_score']\n",
    "mapString2Uniprot.columns=['uniprot_ac_uniprot_id', 'string_id']\n",
    "\n",
    "mapString2Uniprot['uniprot_ac'] = mapString2Uniprot.uniprot_ac_uniprot_id.str.split('|').str[0]\n",
    "\n",
    "dfTrain=pd.merge(dfTrain,mapString2Uniprot,on=['uniprot_ac'],how='left')\n",
    "\n",
    "\n",
    "dfTrain.shape\n",
    "\n",
    "#140 out of 5939 with no string id\n",
    "len(np.nonzero (pd.isna(dfTrain['string_id']))[0])\n",
    "\n",
    "\n",
    "#import pickle\n",
    "\n",
    "# with open('2017/S1_dataset/5939pdataset/dfTrainMapUniprot2String.pickle','wb') as handle:\n",
    "#     pickle.dump(dfTrain,handle)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest=testDataset[[0]]\n",
    "\n",
    "dfTest.columns=['uniprot_ac']\n",
    "\n",
    "\n",
    "mapString2Uniprot=pd.read_csv('../data/all_organisms.uniprot_2_string.2018.tsv',sep='\\t',skiprows=1,usecols=[1,2])\n",
    "\n",
    "\n",
    "#mapString2Uniprot.columns=['species', 'uniprot_ac_uniprot_id', 'string_id', 'identity' ,'bit_score']\n",
    "mapString2Uniprot.columns=['uniprot_ac_uniprot_id', 'string_id']\n",
    "\n",
    "mapString2Uniprot['uniprot_ac'] = mapString2Uniprot.uniprot_ac_uniprot_id.str.split('|').str[0]\n",
    "\n",
    "dfTest=pd.merge(dfTest,mapString2Uniprot,on=['uniprot_ac'],how='left')\n",
    "\n",
    "\n",
    "dfTest.shape\n",
    "\n",
    "#140 out of 5939 with no string id\n",
    "len(np.nonzero (pd.isna(dfTest['string_id']))[0])\n",
    "\n",
    "\n",
    "#import pickle\n",
    "\n",
    "# with open('2017/S1_dataset/5939pdataset/dfTrainMapUniprot2String.pickle','wb') as handle:\n",
    "#     pickle.dump(dfTrain,handle)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('2017/S1_dataset/5939pdataset/dfTrainMapUniprot2String.pickle', \"rb\") as f:\n",
    "#     dfTrain=pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "#proteins_all_humanScore500\n",
    "#proteins_all_human\n",
    "#proteins_all_humanScore300\n",
    "#proteins_all_humanScore400\n",
    "with open('../data/pickles/all_human_stringIDs_19566.pickle', \"rb\") as f:\n",
    "    proteins=pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19566"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0120 14:55:09.523674 139642236327744 deprecation_wrapper.py:119] From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0120 14:55:09.533867 139642236327744 deprecation_wrapper.py:119] From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0120 14:55:09.561540 139642236327744 deprecation_wrapper.py:119] From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0120 14:55:09.561998 139642236327744 deprecation_wrapper.py:119] From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0120 14:55:09.562352 139642236327744 deprecation_wrapper.py:119] From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0120 14:55:10.146781 139642236327744 deprecation_wrapper.py:119] From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#generate_embeddings_10epoch_50d_humanAll\n",
    "#generate_embeddings_10epoch_100d_humanAll_score500\n",
    "#generate_embeddings_10epoch_100d_humanAll\n",
    "#generate_embeddings_10epoch_100d_humanAllBatch2028Epoch5==> 0.77\n",
    "#generate_embeddings_10epoch_100d_humanAll_score500\n",
    "#generate_embeddings_10epoch_50d_humanScore400Batch1024\n",
    "#generate_embeddings_5epoch_50d_humanScore400Batch1024Improved ==> 0.75\n",
    "#generate_embeddings_100epoch_50d_humanScore400Batch1024Improved\n",
    "#generate_embeddings_50epoch5eoch_50d_humanScore400Batch1024Improved\n",
    "#generate_embeddings_1epoch10eoch_50d_humanScore300Batch1024Improved\n",
    "embedding_modebl = load_model('../data/pickles/triplet_embeddings/Final_fineTuned_2017.h5',custom_objects={ 'identity_loss': identity_loss })\n",
    "#embedding_modebl = load_model('../data/pickles/triplet_embeddings/Final_onlyPPI_19566_64d.h5',custom_objects={ 'identity_loss': identity_loss })\n",
    "\n",
    "\n",
    "def generate_vector(model, uid):\n",
    "\n",
    "    vector = model.get_layer('item_embedding').get_weights()[0][uid]\n",
    "    #vector = model.get_layer('embedding_2').get_weights()[0][uid]\n",
    "     \n",
    "\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generate_vector(embedding_modebl,383))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenMax=len(proteins)\n",
    "\n",
    "\n",
    "\n",
    "embedding_size=64\n",
    "\n",
    "testProtein_weights = np.zeros((dfTest.shape[0], embedding_size))\n",
    "\n",
    "testProtein_weights.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5939, 64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenMax=len(proteins)\n",
    "\n",
    "\n",
    "\n",
    "embedding_size=64\n",
    "\n",
    "trainProtein_weights = np.zeros((dfTrain.shape[0], embedding_size))\n",
    "\n",
    "trainProtein_weights.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5939, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_ac</th>\n",
       "      <th>uniprot_ac_uniprot_id</th>\n",
       "      <th>string_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O95866</td>\n",
       "      <td>O95866|G6B_HUMAN</td>\n",
       "      <td>9606.ENSP00000364964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q70Z44</td>\n",
       "      <td>Q70Z44|5HT3D_HUMAN</td>\n",
       "      <td>9606.ENSP00000371929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q5I7T1</td>\n",
       "      <td>Q5I7T1|AG10B_HUMAN</td>\n",
       "      <td>9606.ENSP00000310120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O14514</td>\n",
       "      <td>O14514|AGRB1_HUMAN</td>\n",
       "      <td>9606.ENSP00000430945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q9H159</td>\n",
       "      <td>Q9H159|CAD19_HUMAN</td>\n",
       "      <td>9606.ENSP00000262150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_ac uniprot_ac_uniprot_id             string_id\n",
       "0     O95866      O95866|G6B_HUMAN  9606.ENSP00000364964\n",
       "1     Q70Z44    Q70Z44|5HT3D_HUMAN  9606.ENSP00000371929\n",
       "2     Q5I7T1    Q5I7T1|AG10B_HUMAN  9606.ENSP00000310120\n",
       "3     O14514    O14514|AGRB1_HUMAN  9606.ENSP00000430945\n",
       "4     Q9H159    Q9H159|CAD19_HUMAN  9606.ENSP00000262150"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9606.ENSP00000000233'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proteins[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainProtein_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of found:  902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(920, 64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_found=0\n",
    "for i,row in dfTest.iterrows():\n",
    "    try:\n",
    "        protein_id=np.searchsorted(proteins,row['string_id'])\n",
    "        if protein_id != lenMax:\n",
    "            c_found += 1\n",
    "            testProtein_weights[i]=generate_vector(embedding_modebl,protein_id)\n",
    "        else:\n",
    "            testProtein_weights[i]=np.random.rand(embedding_size)\n",
    "    except:\n",
    "            testProtein_weights[i]=np.random.rand(embedding_size)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print('number of found: ',c_found)\n",
    "\n",
    "testProtein_weights=pd.DataFrame(testProtein_weights)\n",
    "\n",
    "testProtein_weights.shape\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of found:  5799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5939, 64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_found=0\n",
    "for i,row in dfTrain.iterrows():\n",
    "    try:\n",
    "        protein_id=np.searchsorted(proteins,row['string_id'])\n",
    "        if protein_id != lenMax:\n",
    "            c_found += 1\n",
    "            trainProtein_weights[i]=generate_vector(embedding_modebl,protein_id)\n",
    "        else:\n",
    "            trainProtein_weights[i]=np.random.rand(embedding_size)\n",
    "    except:\n",
    "            trainProtein_weights[i]=np.random.rand(embedding_size)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "dfTrain.shape\n",
    "\n",
    "print('number of found: ',c_found)\n",
    "\n",
    "trainProtein_weights=pd.DataFrame(trainProtein_weights)\n",
    "\n",
    "trainProtein_weights.shape\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pickle\n",
    "# with open('2017/S1_dataset/5939pdataset/trainProtein_weights_5939_50d.pickle','wb') as handle:\n",
    "#     pickle.dump(trainProtein_weights,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('2017/S1_dataset/5939pdataset/trainProtein_weights_5939_50d.pickle', \"rb\") as f:\n",
    "#     trainProtein_weights=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=trainProtein_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=testProtein_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testProtein_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testProtein_weights=np.array(testProtein_weights)\n",
    "X_testMultiplx=testProtein_weights[multiplexProteinsIndices]\n",
    "\n",
    "trainProtein_weights=np.array(trainProtein_weights)\n",
    "X_trainMultiplx=trainProtein_weights[multiplexProteinsIndicesTrain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913, 64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainMultiplx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_idx = set(multiplexProteinsIndicesTrain)  #Set is more efficient, but doesn't reorder your elements if that is desireable\n",
    "mask = np.array([(i in include_idx) for i in range(len(trainProtein_weights))])\n",
    "X_trainSingleplex=trainProtein_weights[~mask]\n",
    "y_trainSingleplex=trainLablesOneHot[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=np.array(X_test)\n",
    "\n",
    "y_train=trainLablesOneHot\n",
    "y_trainMultiplex=trainLablesOneHotMultiplex\n",
    "y_train.shape\n",
    "\n",
    "y_test=testLablesOneHot\n",
    "\n",
    "y_testMultiplex=testLablesOneHotMultiplex\n",
    "\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "network=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  computeAbsoluteAccuracyPerLable_single(Ytrue,Ypred):\n",
    "    countSingle=0\n",
    "    countSingleCorrect=0\n",
    "    countMultiple=0\n",
    "    countMultipleCorrect=0\n",
    "    for i in range(6):\n",
    "        print(':',len(np.nonzero (Ytrue[:,i])[0]))\n",
    "    YpredOneHot=np.zeros(shape=(Ypred.shape))\n",
    "    results=[]\n",
    "    rows=Ytrue.shape[0]\n",
    "    for i in range(rows):\n",
    "        numLables=len(np.nonzero (Ytrue[i])[0])\n",
    "        ind = np.argpartition(Ypred[i], -numLables)[-numLables:]\n",
    "        YpredOneHot[i][ind]=1\n",
    "        if numLables>1:\n",
    "            countMultiple+=1\n",
    "            if not any (np.logical_xor (YpredOneHot[i],Ytrue[i])):\n",
    "                \n",
    "                countMultipleCorrect+=1\n",
    "        else:\n",
    "            countSingle+=1\n",
    "            if  not any (np.logical_xor (YpredOneHot[i],Ytrue[i])):\n",
    "                countSingleCorrect+=1\n",
    "            \n",
    "    for i in range(6):\n",
    "        corrects=len(np.nonzero(np.logical_and(Ytrue[:,i], YpredOneHot[:,i]))[0])\n",
    "        numAllTrues=len(np.nonzero (Ytrue[:,i])[0])\n",
    "        #this class has no sample\n",
    "        if  numAllTrues==0:\n",
    "                continue\n",
    "        results.append(corrects/numAllTrues)\n",
    "    print('countSingleCorrect',countSingleCorrect)\n",
    "    print('countSingleCorrect',countSingle)\n",
    "    \n",
    "    return results,(countSingleCorrect/countSingle) ,1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  computeAbsoluteAccuracyPerLable(Ytrue,Ypred):\n",
    "    countSingle=0\n",
    "    countSingleCorrect=0\n",
    "    countMultiple=0\n",
    "    countMultipleCorrect=0\n",
    "    for i in range(6):\n",
    "        print(':',len(np.nonzero (Ytrue[:,i])[0]))\n",
    "    YpredOneHot=np.zeros(shape=(Ypred.shape))\n",
    "    results=[]\n",
    "    rows=Ytrue.shape[0]\n",
    "    for i in range(rows):\n",
    "        numLables=len(np.nonzero (Ytrue[i])[0])\n",
    "        ind = np.argpartition(Ypred[i], -numLables)[-numLables:]\n",
    "        YpredOneHot[i][ind]=1\n",
    "        if numLables>1:\n",
    "            countMultiple+=1\n",
    "            if not any (np.logical_xor (YpredOneHot[i],Ytrue[i])):\n",
    "                \n",
    "                countMultipleCorrect+=1\n",
    "        else:\n",
    "            countSingle+=1\n",
    "            if  not any (np.logical_xor (YpredOneHot[i],Ytrue[i])):\n",
    "                countSingleCorrect+=1\n",
    "            \n",
    "    for i in range(6):\n",
    "        corrects=len(np.nonzero(np.logical_and(Ytrue[:,i], YpredOneHot[:,i]))[0])\n",
    "        numAllTrues=len(np.nonzero (Ytrue[:,i])[0])\n",
    "        #this class has no sample\n",
    "        if  numAllTrues==0:\n",
    "                continue\n",
    "        results.append(corrects/numAllTrues)\n",
    "    print('countSingleCorrect',countSingleCorrect)\n",
    "    print('countSingleCorrect',countSingle)\n",
    "    \n",
    "    return results,(countSingleCorrect/countSingle) ,(countMultipleCorrect/countMultiple)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  computeAbsoluteAccuracy(Ytrue,Ypred):\n",
    "    YpredOneHot=np.zeros(shape=(Ypred.shape))\n",
    "    rows=Ytrue.shape[0]\n",
    "    for i in range(rows):\n",
    "        numLables=len(np.nonzero (Ytrue[i])[0])\n",
    "        ind = np.argpartition(Ypred[i], -numLables)[-numLables:]\n",
    "        YpredOneHot[i][ind]=1\n",
    "    return  accuracy_score(Ytrue,YpredOneHot)   \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, io\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Conv1D,GlobalMaxPooling1D,MaxPooling1D,Dropout,Flatten\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras.layers  import  Conv1D,GlobalAveragePooling1D,Dense,Dropout,MaxPooling1D,GlobalMaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train=np.expand_dims(X_train,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5939, 64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModelNaive():\n",
    "    network = models.Sequential()\n",
    "    \n",
    "    #network.add(Conv1D(50, 7, activation='relu', input_shape=(100, 1),padding='valid'))\n",
    "    \n",
    "    \n",
    "    network.add(layers.Dense(128, activation='relu', input_shape=(64, )))\n",
    "    network.add(layers.Dense(64, activation='relu', ))\n",
    "   \n",
    "    \n",
    "    network.add(layers.Dense(6, activation='softmax'))\n",
    "    opt=optimizers.rmsprop(lr=0.0001)\n",
    "    #opt=optimizers.Adam (lr=0.0001)\n",
    "    network.compile(optimizer=opt,\n",
    "                #loss='binary_crossentropy',\n",
    "                    loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed=1311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model_lstm_attention(W_train,Y_train,epochs):\n",
    "    prec_list=[]; reca_list=[]; fscore_list=[] ; fold=0\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=random_seed,shuffle=True)\n",
    "    #skf = StratifiedKFold(n_splits=5, random_state=random_seed,shuffle=False)\n",
    "    AccuracyMultiple=0\n",
    "    AccuracySingle=0\n",
    "    all_histories=[]\n",
    "    Y = [np.argmax(y, axis=None, out=None) for y in Y_train]\n",
    "    for train_index, test_index in skf.split(W_train,Y):     \n",
    "        fold+=1\n",
    "        X_train, X_test = W_train[train_index], W_train[test_index] \n",
    "        y_train, y_test = Y_train[train_index], Y_train[test_index]\n",
    "        model = None # Clearing the NN.\n",
    "        #model = build_model()\n",
    "        model = buildModelNaive()\n",
    "        #earlystopper = EarlyStopping(monitor='val_loss', patience=2, verbose=0)        \n",
    "\n",
    "        history=model.fit(X_train, y_train, validation_data=(X_test,y_test) ,epochs=epochs, batch_size=16,verbose=1)\n",
    "        \n",
    "        all_histories.append(history)\n",
    "        \n",
    "        YtestPredicted=model.predict(X_test)\n",
    "        \n",
    "    #    avePrec =label_ranking_average_precision_score(y_test, YtestPredicted)\n",
    "    \n",
    "        #avePrec =computeAbsoluteAccuracy(y_test, YtestPredicted)\n",
    "        \n",
    "        #avePrec,AS,AM=computeAbsoluteAccuracyPerLable(y_test, YtestPredicted)\n",
    "        avePrec,AS,AM=computeAbsoluteAccuracyPerLable_single(y_test, YtestPredicted)\n",
    "        AccuracySingle+=AS\n",
    "        AccuracyMultiple+=AM\n",
    "        print(avePrec)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "#         print(\"Fold {:d}: Precision:{:.2f}% \".format(i,np.mean( avePrec*100)))\n",
    "        #prec_list.append(np.mean(avePrec))\n",
    "        prec_list.append(avePrec)\n",
    "    \n",
    "#     precission=sum(prec_list)/len(prec_list)*100 \n",
    "#     print(\"Final: Precision:{:.2f}% \".format(precission ))\n",
    "    return prec_list,(AccuracySingle/5),(AccuracyMultiple/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0120 14:55:30.798146 139642236327744 deprecation.py:323] From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4748 samples, validate on 1191 samples\n",
      "Epoch 1/30\n",
      "4748/4748 [==============================] - 1s 143us/step - loss: 1.6254 - acc: 0.4650 - val_loss: 1.2863 - val_acc: 0.6054\n",
      "Epoch 2/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 1.1417 - acc: 0.6563 - val_loss: 1.0536 - val_acc: 0.6893\n",
      "Epoch 3/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.9917 - acc: 0.7087 - val_loss: 0.9692 - val_acc: 0.7095\n",
      "Epoch 4/30\n",
      "4748/4748 [==============================] - 0s 82us/step - loss: 0.9280 - acc: 0.7260 - val_loss: 0.9302 - val_acc: 0.7196\n",
      "Epoch 5/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.8936 - acc: 0.7348 - val_loss: 0.9100 - val_acc: 0.7263\n",
      "Epoch 6/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.8707 - acc: 0.7437 - val_loss: 0.8936 - val_acc: 0.7280\n",
      "Epoch 7/30\n",
      "4748/4748 [==============================] - 0s 80us/step - loss: 0.8532 - acc: 0.7553 - val_loss: 0.8782 - val_acc: 0.7355\n",
      "Epoch 8/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.8387 - acc: 0.7542 - val_loss: 0.8677 - val_acc: 0.7355\n",
      "Epoch 9/30\n",
      "4748/4748 [==============================] - 0s 82us/step - loss: 0.8267 - acc: 0.7607 - val_loss: 0.8611 - val_acc: 0.7355\n",
      "Epoch 10/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.8170 - acc: 0.7631 - val_loss: 0.8542 - val_acc: 0.7372\n",
      "Epoch 11/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.8061 - acc: 0.7641 - val_loss: 0.8482 - val_acc: 0.7431\n",
      "Epoch 12/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7988 - acc: 0.7681 - val_loss: 0.8400 - val_acc: 0.7498\n",
      "Epoch 13/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7904 - acc: 0.7753 - val_loss: 0.8357 - val_acc: 0.7498\n",
      "Epoch 14/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7826 - acc: 0.7810 - val_loss: 0.8325 - val_acc: 0.7498\n",
      "Epoch 15/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7760 - acc: 0.7765 - val_loss: 0.8278 - val_acc: 0.7506\n",
      "Epoch 16/30\n",
      "4748/4748 [==============================] - 0s 80us/step - loss: 0.7693 - acc: 0.7793 - val_loss: 0.8259 - val_acc: 0.7540\n",
      "Epoch 17/30\n",
      "4748/4748 [==============================] - 0s 82us/step - loss: 0.7636 - acc: 0.7829 - val_loss: 0.8205 - val_acc: 0.7557\n",
      "Epoch 18/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7568 - acc: 0.7858 - val_loss: 0.8157 - val_acc: 0.7624\n",
      "Epoch 19/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7526 - acc: 0.7892 - val_loss: 0.8145 - val_acc: 0.7590\n",
      "Epoch 20/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7476 - acc: 0.7888 - val_loss: 0.8114 - val_acc: 0.7641\n",
      "Epoch 21/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7427 - acc: 0.7900 - val_loss: 0.8073 - val_acc: 0.7607\n",
      "Epoch 22/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7381 - acc: 0.7911 - val_loss: 0.8049 - val_acc: 0.7699\n",
      "Epoch 23/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7338 - acc: 0.7949 - val_loss: 0.8032 - val_acc: 0.7607\n",
      "Epoch 24/30\n",
      "4748/4748 [==============================] - 0s 82us/step - loss: 0.7289 - acc: 0.7932 - val_loss: 0.8023 - val_acc: 0.7691\n",
      "Epoch 25/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7253 - acc: 0.7968 - val_loss: 0.7976 - val_acc: 0.7683\n",
      "Epoch 26/30\n",
      "4748/4748 [==============================] - 0s 80us/step - loss: 0.7210 - acc: 0.7987 - val_loss: 0.7967 - val_acc: 0.7649\n",
      "Epoch 27/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7176 - acc: 0.7999 - val_loss: 0.7939 - val_acc: 0.7666\n",
      "Epoch 28/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7133 - acc: 0.8014 - val_loss: 0.7930 - val_acc: 0.7699\n",
      "Epoch 29/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7097 - acc: 0.8031 - val_loss: 0.7930 - val_acc: 0.7733\n",
      "Epoch 30/30\n",
      "4748/4748 [==============================] - 0s 81us/step - loss: 0.7064 - acc: 0.8058 - val_loss: 0.7944 - val_acc: 0.7666\n",
      ": 291\n",
      ": 316\n",
      ": 115\n",
      ": 91\n",
      ": 404\n",
      ": 164\n",
      "countSingleCorrect 856\n",
      "countSingleCorrect 1005\n",
      "[0.8247422680412371, 0.8132911392405063, 0.7043478260869566, 0.9120879120879121, 0.9257425742574258, 0.7865853658536586]\n",
      "Train on 4750 samples, validate on 1189 samples\n",
      "Epoch 1/30\n",
      "4750/4750 [==============================] - 1s 114us/step - loss: 1.6268 - acc: 0.4811 - val_loss: 1.2671 - val_acc: 0.6140\n",
      "Epoch 2/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 1.1290 - acc: 0.6600 - val_loss: 1.0049 - val_acc: 0.6897\n",
      "Epoch 3/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.9828 - acc: 0.7107 - val_loss: 0.9175 - val_acc: 0.7241\n",
      "Epoch 4/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.9269 - acc: 0.7261 - val_loss: 0.8796 - val_acc: 0.7300\n",
      "Epoch 5/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.8972 - acc: 0.7352 - val_loss: 0.8587 - val_acc: 0.7393\n",
      "Epoch 6/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.8770 - acc: 0.7392 - val_loss: 0.8449 - val_acc: 0.7519\n",
      "Epoch 7/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.8601 - acc: 0.7463 - val_loss: 0.8346 - val_acc: 0.7502\n",
      "Epoch 8/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.8466 - acc: 0.7524 - val_loss: 0.8267 - val_acc: 0.7519\n",
      "Epoch 9/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.8356 - acc: 0.7543 - val_loss: 0.8178 - val_acc: 0.7595\n",
      "Epoch 10/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.8241 - acc: 0.7621 - val_loss: 0.8175 - val_acc: 0.7662\n",
      "Epoch 11/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.8153 - acc: 0.7617 - val_loss: 0.8060 - val_acc: 0.7653\n",
      "Epoch 12/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.8065 - acc: 0.7657 - val_loss: 0.8018 - val_acc: 0.7721\n",
      "Epoch 13/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.7984 - acc: 0.7722 - val_loss: 0.7972 - val_acc: 0.7696\n",
      "Epoch 14/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.7912 - acc: 0.7712 - val_loss: 0.7956 - val_acc: 0.7696\n",
      "Epoch 15/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.7843 - acc: 0.7739 - val_loss: 0.7942 - val_acc: 0.7738\n",
      "Epoch 16/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.7778 - acc: 0.7764 - val_loss: 0.7902 - val_acc: 0.7738\n",
      "Epoch 17/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.7718 - acc: 0.7804 - val_loss: 0.7856 - val_acc: 0.7696\n",
      "Epoch 18/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.7660 - acc: 0.7827 - val_loss: 0.7849 - val_acc: 0.7738\n",
      "Epoch 19/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.7603 - acc: 0.7880 - val_loss: 0.7829 - val_acc: 0.7679\n",
      "Epoch 20/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.7551 - acc: 0.7893 - val_loss: 0.7797 - val_acc: 0.7796\n",
      "Epoch 21/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.7497 - acc: 0.7901 - val_loss: 0.7768 - val_acc: 0.7738\n",
      "Epoch 22/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.7450 - acc: 0.7952 - val_loss: 0.7781 - val_acc: 0.7754\n",
      "Epoch 23/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.7406 - acc: 0.7947 - val_loss: 0.7752 - val_acc: 0.7813\n",
      "Epoch 24/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.7360 - acc: 0.7968 - val_loss: 0.7730 - val_acc: 0.7788\n",
      "Epoch 25/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.7314 - acc: 0.7966 - val_loss: 0.7700 - val_acc: 0.7771\n",
      "Epoch 26/30\n",
      "4750/4750 [==============================] - 0s 80us/step - loss: 0.7274 - acc: 0.7977 - val_loss: 0.7687 - val_acc: 0.7822\n",
      "Epoch 27/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.7234 - acc: 0.8013 - val_loss: 0.7684 - val_acc: 0.7780\n",
      "Epoch 28/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.7195 - acc: 0.8015 - val_loss: 0.7661 - val_acc: 0.7847\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.7154 - acc: 0.8048 - val_loss: 0.7688 - val_acc: 0.7830\n",
      "Epoch 30/30\n",
      "4750/4750 [==============================] - 0s 81us/step - loss: 0.7118 - acc: 0.8046 - val_loss: 0.7652 - val_acc: 0.7805\n",
      ": 291\n",
      ": 308\n",
      ": 110\n",
      ": 94\n",
      ": 416\n",
      ": 158\n",
      "countSingleCorrect 859\n",
      "countSingleCorrect 1008\n",
      "[0.8247422680412371, 0.827922077922078, 0.7454545454545455, 0.8085106382978723, 0.9158653846153846, 0.8291139240506329]\n",
      "Train on 4752 samples, validate on 1187 samples\n",
      "Epoch 1/30\n",
      "4752/4752 [==============================] - 1s 119us/step - loss: 1.6479 - acc: 0.4973 - val_loss: 1.2889 - val_acc: 0.6243\n",
      "Epoch 2/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 1.1675 - acc: 0.6439 - val_loss: 1.0116 - val_acc: 0.7287\n",
      "Epoch 3/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.9997 - acc: 0.6955 - val_loss: 0.9262 - val_acc: 0.7489\n",
      "Epoch 4/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.9373 - acc: 0.7085 - val_loss: 0.8908 - val_acc: 0.7523\n",
      "Epoch 5/30\n",
      "4752/4752 [==============================] - 0s 82us/step - loss: 0.9043 - acc: 0.7197 - val_loss: 0.8700 - val_acc: 0.7633\n",
      "Epoch 6/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.8819 - acc: 0.7279 - val_loss: 0.8547 - val_acc: 0.7717\n",
      "Epoch 7/30\n",
      "4752/4752 [==============================] - 0s 82us/step - loss: 0.8649 - acc: 0.7388 - val_loss: 0.8449 - val_acc: 0.7734\n",
      "Epoch 8/30\n",
      "4752/4752 [==============================] - 0s 82us/step - loss: 0.8504 - acc: 0.7447 - val_loss: 0.8361 - val_acc: 0.7709\n",
      "Epoch 9/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.8390 - acc: 0.7498 - val_loss: 0.8282 - val_acc: 0.7801\n",
      "Epoch 10/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.8277 - acc: 0.7555 - val_loss: 0.8187 - val_acc: 0.7751\n",
      "Epoch 11/30\n",
      "4752/4752 [==============================] - 0s 80us/step - loss: 0.8182 - acc: 0.7588 - val_loss: 0.8132 - val_acc: 0.7826\n",
      "Epoch 12/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.8087 - acc: 0.7612 - val_loss: 0.8111 - val_acc: 0.7869\n",
      "Epoch 13/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.8008 - acc: 0.7637 - val_loss: 0.8020 - val_acc: 0.7877\n",
      "Epoch 14/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7931 - acc: 0.7702 - val_loss: 0.8004 - val_acc: 0.7885\n",
      "Epoch 15/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7859 - acc: 0.7719 - val_loss: 0.7944 - val_acc: 0.7894\n",
      "Epoch 16/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7798 - acc: 0.7746 - val_loss: 0.7905 - val_acc: 0.7894\n",
      "Epoch 17/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7729 - acc: 0.7753 - val_loss: 0.7905 - val_acc: 0.7936\n",
      "Epoch 18/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7669 - acc: 0.7786 - val_loss: 0.7842 - val_acc: 0.7902\n",
      "Epoch 19/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7612 - acc: 0.7828 - val_loss: 0.7887 - val_acc: 0.8029\n",
      "Epoch 20/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7567 - acc: 0.7841 - val_loss: 0.7799 - val_acc: 0.7936\n",
      "Epoch 21/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7516 - acc: 0.7872 - val_loss: 0.7769 - val_acc: 0.7987\n",
      "Epoch 22/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7465 - acc: 0.7891 - val_loss: 0.7786 - val_acc: 0.7944\n",
      "Epoch 23/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7424 - acc: 0.7906 - val_loss: 0.7780 - val_acc: 0.8037\n",
      "Epoch 24/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7374 - acc: 0.7938 - val_loss: 0.7706 - val_acc: 0.7995\n",
      "Epoch 25/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7337 - acc: 0.7940 - val_loss: 0.7704 - val_acc: 0.7995\n",
      "Epoch 26/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7298 - acc: 0.7961 - val_loss: 0.7721 - val_acc: 0.7987\n",
      "Epoch 27/30\n",
      "4752/4752 [==============================] - 0s 80us/step - loss: 0.7257 - acc: 0.7971 - val_loss: 0.7689 - val_acc: 0.8020\n",
      "Epoch 28/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7221 - acc: 0.8005 - val_loss: 0.7674 - val_acc: 0.8029\n",
      "Epoch 29/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7187 - acc: 0.7988 - val_loss: 0.7674 - val_acc: 0.8045\n",
      "Epoch 30/30\n",
      "4752/4752 [==============================] - 0s 81us/step - loss: 0.7143 - acc: 0.8009 - val_loss: 0.7662 - val_acc: 0.7987\n",
      ": 291\n",
      ": 302\n",
      ": 113\n",
      ": 90\n",
      ": 402\n",
      ": 158\n",
      "countSingleCorrect 871\n",
      "countSingleCorrect 1022\n",
      "[0.9037800687285223, 0.7847682119205298, 0.7345132743362832, 0.7888888888888889, 0.9203980099502488, 0.7911392405063291]\n",
      "Train on 4753 samples, validate on 1186 samples\n",
      "Epoch 1/30\n",
      "4753/4753 [==============================] - 1s 124us/step - loss: 1.5714 - acc: 0.5134 - val_loss: 1.2502 - val_acc: 0.6164\n",
      "Epoch 2/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 1.1218 - acc: 0.6541 - val_loss: 1.0476 - val_acc: 0.6796\n",
      "Epoch 3/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 0.9911 - acc: 0.6996 - val_loss: 0.9781 - val_acc: 0.7209\n",
      "Epoch 4/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.9302 - acc: 0.7191 - val_loss: 0.9451 - val_acc: 0.7302\n",
      "Epoch 5/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 0.8957 - acc: 0.7351 - val_loss: 0.9219 - val_acc: 0.7487\n",
      "Epoch 6/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8709 - acc: 0.7479 - val_loss: 0.9098 - val_acc: 0.7462\n",
      "Epoch 7/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8536 - acc: 0.7494 - val_loss: 0.8973 - val_acc: 0.7572\n",
      "Epoch 8/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8389 - acc: 0.7555 - val_loss: 0.8871 - val_acc: 0.7555\n",
      "Epoch 9/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8268 - acc: 0.7599 - val_loss: 0.8800 - val_acc: 0.7546\n",
      "Epoch 10/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8158 - acc: 0.7623 - val_loss: 0.8725 - val_acc: 0.7538\n",
      "Epoch 11/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8066 - acc: 0.7606 - val_loss: 0.8683 - val_acc: 0.7648\n",
      "Epoch 12/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 0.7973 - acc: 0.7648 - val_loss: 0.8639 - val_acc: 0.7690\n",
      "Epoch 13/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 0.7900 - acc: 0.7711 - val_loss: 0.8562 - val_acc: 0.7681\n",
      "Epoch 14/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 0.7822 - acc: 0.7755 - val_loss: 0.8553 - val_acc: 0.7648\n",
      "Epoch 15/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 0.7756 - acc: 0.7747 - val_loss: 0.8491 - val_acc: 0.7673\n",
      "Epoch 16/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 0.7688 - acc: 0.7747 - val_loss: 0.8449 - val_acc: 0.7791\n",
      "Epoch 17/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7635 - acc: 0.7816 - val_loss: 0.8431 - val_acc: 0.7589\n",
      "Epoch 18/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 0.7574 - acc: 0.7808 - val_loss: 0.8375 - val_acc: 0.7799\n",
      "Epoch 19/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7519 - acc: 0.7835 - val_loss: 0.8399 - val_acc: 0.7707\n",
      "Epoch 20/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7473 - acc: 0.7856 - val_loss: 0.8313 - val_acc: 0.7858\n",
      "Epoch 21/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7418 - acc: 0.7860 - val_loss: 0.8319 - val_acc: 0.7833\n",
      "Epoch 22/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7379 - acc: 0.7919 - val_loss: 0.8279 - val_acc: 0.7875\n",
      "Epoch 23/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 0.7329 - acc: 0.7919 - val_loss: 0.8233 - val_acc: 0.7816\n",
      "Epoch 24/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 0.7283 - acc: 0.7949 - val_loss: 0.8235 - val_acc: 0.7884\n",
      "Epoch 25/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7247 - acc: 0.7934 - val_loss: 0.8214 - val_acc: 0.7875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 0.7205 - acc: 0.7949 - val_loss: 0.8184 - val_acc: 0.7841\n",
      "Epoch 27/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7160 - acc: 0.7957 - val_loss: 0.8179 - val_acc: 0.7884\n",
      "Epoch 28/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7131 - acc: 0.7993 - val_loss: 0.8130 - val_acc: 0.7858\n",
      "Epoch 29/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 0.7094 - acc: 0.8016 - val_loss: 0.8168 - val_acc: 0.7884\n",
      "Epoch 30/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7059 - acc: 0.8020 - val_loss: 0.8137 - val_acc: 0.7892\n",
      ": 290\n",
      ": 310\n",
      ": 112\n",
      ": 94\n",
      ": 419\n",
      ": 158\n",
      "countSingleCorrect 851\n",
      "countSingleCorrect 998\n",
      "[0.8620689655172413, 0.8483870967741935, 0.8214285714285714, 0.8191489361702128, 0.8782816229116945, 0.7531645569620253]\n",
      "Train on 4753 samples, validate on 1186 samples\n",
      "Epoch 1/30\n",
      "4753/4753 [==============================] - 1s 129us/step - loss: 1.5747 - acc: 0.4599 - val_loss: 1.2725 - val_acc: 0.5666\n",
      "Epoch 2/30\n",
      "4753/4753 [==============================] - 0s 81us/step - loss: 1.1145 - acc: 0.6672 - val_loss: 1.0411 - val_acc: 0.6771\n",
      "Epoch 3/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.9690 - acc: 0.7256 - val_loss: 0.9650 - val_acc: 0.6998\n",
      "Epoch 4/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.9136 - acc: 0.7376 - val_loss: 0.9319 - val_acc: 0.7049\n",
      "Epoch 5/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8838 - acc: 0.7450 - val_loss: 0.9094 - val_acc: 0.7218\n",
      "Epoch 6/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8624 - acc: 0.7547 - val_loss: 0.8966 - val_acc: 0.7116\n",
      "Epoch 7/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8470 - acc: 0.7593 - val_loss: 0.8809 - val_acc: 0.7192\n",
      "Epoch 8/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8336 - acc: 0.7639 - val_loss: 0.8709 - val_acc: 0.7260\n",
      "Epoch 9/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8214 - acc: 0.7705 - val_loss: 0.8626 - val_acc: 0.7268\n",
      "Epoch 10/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8121 - acc: 0.7724 - val_loss: 0.8553 - val_acc: 0.7336\n",
      "Epoch 11/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.8024 - acc: 0.7764 - val_loss: 0.8491 - val_acc: 0.7327\n",
      "Epoch 12/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7943 - acc: 0.7774 - val_loss: 0.8448 - val_acc: 0.7403\n",
      "Epoch 13/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7851 - acc: 0.7812 - val_loss: 0.8403 - val_acc: 0.7327\n",
      "Epoch 14/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7782 - acc: 0.7862 - val_loss: 0.8401 - val_acc: 0.7470\n",
      "Epoch 15/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7716 - acc: 0.7881 - val_loss: 0.8305 - val_acc: 0.7437\n",
      "Epoch 16/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7653 - acc: 0.7873 - val_loss: 0.8292 - val_acc: 0.7563\n",
      "Epoch 17/30\n",
      "4753/4753 [==============================] - 0s 83us/step - loss: 0.7595 - acc: 0.7932 - val_loss: 0.8236 - val_acc: 0.7445\n",
      "Epoch 18/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7528 - acc: 0.7911 - val_loss: 0.8217 - val_acc: 0.7538\n",
      "Epoch 19/30\n",
      "4753/4753 [==============================] - 0s 83us/step - loss: 0.7475 - acc: 0.7951 - val_loss: 0.8202 - val_acc: 0.7513\n",
      "Epoch 20/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7421 - acc: 0.7961 - val_loss: 0.8150 - val_acc: 0.7530\n",
      "Epoch 21/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7374 - acc: 0.7999 - val_loss: 0.8138 - val_acc: 0.7530\n",
      "Epoch 22/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7332 - acc: 0.8020 - val_loss: 0.8129 - val_acc: 0.7605\n",
      "Epoch 23/30\n",
      "4753/4753 [==============================] - 0s 83us/step - loss: 0.7283 - acc: 0.8027 - val_loss: 0.8096 - val_acc: 0.7605\n",
      "Epoch 24/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7238 - acc: 0.8024 - val_loss: 0.8093 - val_acc: 0.7479\n",
      "Epoch 25/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7203 - acc: 0.8062 - val_loss: 0.8065 - val_acc: 0.7589\n",
      "Epoch 26/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7168 - acc: 0.8058 - val_loss: 0.8057 - val_acc: 0.7656\n",
      "Epoch 27/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7122 - acc: 0.8081 - val_loss: 0.8049 - val_acc: 0.7614\n",
      "Epoch 28/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7089 - acc: 0.8104 - val_loss: 0.8043 - val_acc: 0.7698\n",
      "Epoch 29/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7052 - acc: 0.8100 - val_loss: 0.8021 - val_acc: 0.7622\n",
      "Epoch 30/30\n",
      "4753/4753 [==============================] - 0s 82us/step - loss: 0.7014 - acc: 0.8109 - val_loss: 0.8069 - val_acc: 0.7639\n",
      ": 290\n",
      ": 306\n",
      ": 112\n",
      ": 93\n",
      ": 423\n",
      ": 157\n",
      "countSingleCorrect 815\n",
      "countSingleCorrect 993\n",
      "[0.8724137931034482, 0.8169934640522876, 0.7678571428571429, 0.7741935483870968, 0.9125295508274232, 0.6496815286624203]\n"
     ]
    }
   ],
   "source": [
    "#generate_embeddings_10epoch_50d_humanAll    ==> 0.7325441305244833\n",
    "#generate_embeddings_10epoch_100d_humanAll_score500  ==>0.65\n",
    "#generate_embeddings_10epoch_100d_humanAll   ==> 0.7324315902459138\n",
    "#generate_embeddings_10epoch_100d_humanAllBatch2028Epoch5  ==> 0.7359638809890722\n",
    "\n",
    "re,AccuracySingle,AccuracyMultiple=train_and_evaluate_model_lstm_attention(X_train,y_train,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4748 samples, validate on 1191 samples\n",
      "Epoch 1/30\n",
      "4748/4748 [==============================] - 2s 384us/step - loss: 1.7324 - acc: 0.4604 - val_loss: 1.4987 - val_acc: 0.5248\n",
      "Epoch 2/30\n",
      "4748/4748 [==============================] - 1s 312us/step - loss: 1.3403 - acc: 0.5672 - val_loss: 1.2779 - val_acc: 0.5970\n",
      "Epoch 3/30\n",
      "4748/4748 [==============================] - 1s 309us/step - loss: 1.1963 - acc: 0.6118 - val_loss: 1.1849 - val_acc: 0.6247\n",
      "Epoch 4/30\n",
      "4748/4748 [==============================] - 2s 316us/step - loss: 1.1325 - acc: 0.6340 - val_loss: 1.1359 - val_acc: 0.6440\n",
      "Epoch 5/30\n",
      "4748/4748 [==============================] - 1s 312us/step - loss: 1.0971 - acc: 0.6453 - val_loss: 1.1087 - val_acc: 0.6541\n",
      "Epoch 6/30\n",
      "4748/4748 [==============================] - 1s 294us/step - loss: 1.0736 - acc: 0.6512 - val_loss: 1.0877 - val_acc: 0.6558\n",
      "Epoch 7/30\n",
      "4748/4748 [==============================] - 1s 313us/step - loss: 1.0571 - acc: 0.6582 - val_loss: 1.0749 - val_acc: 0.6658\n",
      "Epoch 8/30\n",
      "4748/4748 [==============================] - 1s 311us/step - loss: 1.0438 - acc: 0.6634 - val_loss: 1.0660 - val_acc: 0.6734\n",
      "Epoch 9/30\n",
      "4748/4748 [==============================] - 1s 308us/step - loss: 1.0337 - acc: 0.6636 - val_loss: 1.0592 - val_acc: 0.6717\n",
      "Epoch 10/30\n",
      "4748/4748 [==============================] - 1s 311us/step - loss: 1.0242 - acc: 0.6683 - val_loss: 1.0518 - val_acc: 0.6725\n",
      "Epoch 11/30\n",
      "4748/4748 [==============================] - 1s 311us/step - loss: 1.0155 - acc: 0.6740 - val_loss: 1.0524 - val_acc: 0.6675\n",
      "Epoch 12/30\n",
      "4748/4748 [==============================] - 1s 312us/step - loss: 1.0088 - acc: 0.6761 - val_loss: 1.0429 - val_acc: 0.6700\n",
      "Epoch 13/30\n",
      "4748/4748 [==============================] - 1s 315us/step - loss: 1.0015 - acc: 0.6765 - val_loss: 1.0411 - val_acc: 0.6767\n",
      "Epoch 14/30\n",
      "4748/4748 [==============================] - 1s 312us/step - loss: 0.9956 - acc: 0.6816 - val_loss: 1.0363 - val_acc: 0.6725\n",
      "Epoch 15/30\n",
      "4748/4748 [==============================] - 1s 315us/step - loss: 0.9903 - acc: 0.6826 - val_loss: 1.0364 - val_acc: 0.6725\n",
      "Epoch 16/30\n",
      "4748/4748 [==============================] - 2s 317us/step - loss: 0.9852 - acc: 0.6853 - val_loss: 1.0347 - val_acc: 0.6776\n",
      "Epoch 17/30\n",
      "4748/4748 [==============================] - 1s 313us/step - loss: 0.9796 - acc: 0.6902 - val_loss: 1.0322 - val_acc: 0.6767\n",
      "Epoch 18/30\n",
      "4748/4748 [==============================] - 1s 311us/step - loss: 0.9747 - acc: 0.6904 - val_loss: 1.0266 - val_acc: 0.6767\n",
      "Epoch 19/30\n",
      "4748/4748 [==============================] - 1s 308us/step - loss: 0.9703 - acc: 0.6912 - val_loss: 1.0272 - val_acc: 0.6801\n",
      "Epoch 20/30\n",
      "4748/4748 [==============================] - 1s 310us/step - loss: 0.9655 - acc: 0.6950 - val_loss: 1.0286 - val_acc: 0.6793\n",
      "Epoch 21/30\n",
      "4748/4748 [==============================] - 1s 316us/step - loss: 0.9615 - acc: 0.6952 - val_loss: 1.0256 - val_acc: 0.6843\n",
      "Epoch 22/30\n",
      "4748/4748 [==============================] - 1s 303us/step - loss: 0.9573 - acc: 0.6961 - val_loss: 1.0247 - val_acc: 0.6835\n",
      "Epoch 23/30\n",
      "4748/4748 [==============================] - 1s 314us/step - loss: 0.9531 - acc: 0.6957 - val_loss: 1.0268 - val_acc: 0.6793\n",
      "Epoch 24/30\n",
      "4748/4748 [==============================] - 1s 315us/step - loss: 0.9498 - acc: 0.6986 - val_loss: 1.0203 - val_acc: 0.6843\n",
      "Epoch 25/30\n",
      "4748/4748 [==============================] - 1s 314us/step - loss: 0.9456 - acc: 0.7024 - val_loss: 1.0188 - val_acc: 0.6860\n",
      "Epoch 26/30\n",
      "4748/4748 [==============================] - 1s 312us/step - loss: 0.9422 - acc: 0.7009 - val_loss: 1.0193 - val_acc: 0.6818\n",
      "Epoch 27/30\n",
      "4748/4748 [==============================] - 2s 317us/step - loss: 0.9387 - acc: 0.7047 - val_loss: 1.0196 - val_acc: 0.6860\n",
      "Epoch 28/30\n",
      "4748/4748 [==============================] - 1s 316us/step - loss: 0.9355 - acc: 0.7028 - val_loss: 1.0202 - val_acc: 0.6835\n",
      "Epoch 29/30\n",
      "4748/4748 [==============================] - 1s 306us/step - loss: 0.9322 - acc: 0.7035 - val_loss: 1.0179 - val_acc: 0.6809\n",
      "Epoch 30/30\n",
      "4748/4748 [==============================] - 1s 315us/step - loss: 0.9290 - acc: 0.7060 - val_loss: 1.0172 - val_acc: 0.6851\n",
      ": 291\n",
      ": 316\n",
      ": 113\n",
      ": 91\n",
      ": 419\n",
      ": 165\n",
      "countSingleCorrect 748\n",
      "countSingleCorrect 990\n",
      "[0.7594501718213058, 0.7943037974683544, 0.6106194690265486, 0.7802197802197802, 0.8806682577565632, 0.6424242424242425]\n",
      "Train on 4750 samples, validate on 1189 samples\n",
      "Epoch 1/30\n",
      "4750/4750 [==============================] - 2s 362us/step - loss: 1.7245 - acc: 0.4657 - val_loss: 1.4894 - val_acc: 0.5374\n",
      "Epoch 2/30\n",
      "4750/4750 [==============================] - 2s 316us/step - loss: 1.3384 - acc: 0.5682 - val_loss: 1.2687 - val_acc: 0.5879\n",
      "Epoch 3/30\n",
      "4750/4750 [==============================] - 1s 315us/step - loss: 1.1987 - acc: 0.6044 - val_loss: 1.1958 - val_acc: 0.6173\n",
      "Epoch 4/30\n",
      "4750/4750 [==============================] - 1s 313us/step - loss: 1.1396 - acc: 0.6291 - val_loss: 1.1615 - val_acc: 0.6224\n",
      "Epoch 5/30\n",
      "4750/4750 [==============================] - 1s 304us/step - loss: 1.1057 - acc: 0.6423 - val_loss: 1.1404 - val_acc: 0.6274\n",
      "Epoch 6/30\n",
      "4750/4750 [==============================] - 1s 296us/step - loss: 1.0821 - acc: 0.6486 - val_loss: 1.1265 - val_acc: 0.6325\n",
      "Epoch 7/30\n",
      "4750/4750 [==============================] - 2s 317us/step - loss: 1.0658 - acc: 0.6516 - val_loss: 1.1169 - val_acc: 0.6426\n",
      "Epoch 8/30\n",
      "4750/4750 [==============================] - 1s 315us/step - loss: 1.0532 - acc: 0.6587 - val_loss: 1.1090 - val_acc: 0.6451\n",
      "Epoch 9/30\n",
      "4750/4750 [==============================] - 2s 316us/step - loss: 1.0415 - acc: 0.6611 - val_loss: 1.1041 - val_acc: 0.6468\n",
      "Epoch 10/30\n",
      "4750/4750 [==============================] - 1s 308us/step - loss: 1.0334 - acc: 0.6653 - val_loss: 1.0974 - val_acc: 0.6518\n",
      "Epoch 11/30\n",
      "4750/4750 [==============================] - 1s 308us/step - loss: 1.0251 - acc: 0.6682 - val_loss: 1.0922 - val_acc: 0.6569\n",
      "Epoch 12/30\n",
      "4750/4750 [==============================] - 2s 316us/step - loss: 1.0182 - acc: 0.6752 - val_loss: 1.0887 - val_acc: 0.6585\n",
      "Epoch 13/30\n",
      "4750/4750 [==============================] - 2s 317us/step - loss: 1.0117 - acc: 0.6747 - val_loss: 1.0864 - val_acc: 0.6636\n",
      "Epoch 14/30\n",
      "4750/4750 [==============================] - 2s 317us/step - loss: 1.0058 - acc: 0.6779 - val_loss: 1.0807 - val_acc: 0.6627\n",
      "Epoch 15/30\n",
      "4750/4750 [==============================] - 2s 316us/step - loss: 1.0004 - acc: 0.6762 - val_loss: 1.0780 - val_acc: 0.6644\n",
      "Epoch 16/30\n",
      "4750/4750 [==============================] - 1s 297us/step - loss: 0.9950 - acc: 0.6779 - val_loss: 1.0777 - val_acc: 0.6661\n",
      "Epoch 17/30\n",
      "4750/4750 [==============================] - 1s 314us/step - loss: 0.9901 - acc: 0.6813 - val_loss: 1.0724 - val_acc: 0.6695\n",
      "Epoch 18/30\n",
      "4750/4750 [==============================] - 1s 312us/step - loss: 0.9859 - acc: 0.6825 - val_loss: 1.0703 - val_acc: 0.6703\n",
      "Epoch 19/30\n",
      "4750/4750 [==============================] - 1s 313us/step - loss: 0.9811 - acc: 0.6851 - val_loss: 1.0663 - val_acc: 0.6686\n",
      "Epoch 20/30\n",
      "4750/4750 [==============================] - 1s 297us/step - loss: 0.9767 - acc: 0.6829 - val_loss: 1.0642 - val_acc: 0.6712\n",
      "Epoch 21/30\n",
      "4750/4750 [==============================] - 1s 315us/step - loss: 0.9727 - acc: 0.6891 - val_loss: 1.0620 - val_acc: 0.6695\n",
      "Epoch 22/30\n",
      "4750/4750 [==============================] - 1s 316us/step - loss: 0.9683 - acc: 0.6907 - val_loss: 1.0606 - val_acc: 0.6686\n",
      "Epoch 23/30\n",
      "4750/4750 [==============================] - 1s 312us/step - loss: 0.9651 - acc: 0.6874 - val_loss: 1.0593 - val_acc: 0.6728\n",
      "Epoch 24/30\n",
      "4750/4750 [==============================] - 2s 317us/step - loss: 0.9615 - acc: 0.6903 - val_loss: 1.0557 - val_acc: 0.6812\n",
      "Epoch 25/30\n",
      "4750/4750 [==============================] - 1s 316us/step - loss: 0.9577 - acc: 0.6916 - val_loss: 1.0550 - val_acc: 0.6745\n",
      "Epoch 26/30\n",
      "4750/4750 [==============================] - 1s 316us/step - loss: 0.9545 - acc: 0.6909 - val_loss: 1.0556 - val_acc: 0.6796\n",
      "Epoch 27/30\n",
      "4750/4750 [==============================] - 1s 307us/step - loss: 0.9509 - acc: 0.6928 - val_loss: 1.0524 - val_acc: 0.6762\n",
      "Epoch 28/30\n",
      "4750/4750 [==============================] - 1s 304us/step - loss: 0.9473 - acc: 0.6968 - val_loss: 1.0508 - val_acc: 0.6863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "4750/4750 [==============================] - 2s 318us/step - loss: 0.9444 - acc: 0.6956 - val_loss: 1.0495 - val_acc: 0.6821\n",
      "Epoch 30/30\n",
      "4750/4750 [==============================] - 1s 298us/step - loss: 0.9412 - acc: 0.6989 - val_loss: 1.0470 - val_acc: 0.6821\n",
      ": 291\n",
      ": 308\n",
      ": 114\n",
      ": 95\n",
      ": 411\n",
      ": 163\n",
      "countSingleCorrect 750\n",
      "countSingleCorrect 1004\n",
      "[0.7903780068728522, 0.724025974025974, 0.5701754385964912, 0.7368421052631579, 0.8613138686131386, 0.7055214723926381]\n",
      "Train on 4752 samples, validate on 1187 samples\n",
      "Epoch 1/30\n",
      "4752/4752 [==============================] - 2s 349us/step - loss: 1.8318 - acc: 0.3950 - val_loss: 1.4996 - val_acc: 0.5324\n",
      "Epoch 2/30\n",
      "4752/4752 [==============================] - 2s 316us/step - loss: 1.4030 - acc: 0.5377 - val_loss: 1.2372 - val_acc: 0.5914\n",
      "Epoch 3/30\n",
      "4752/4752 [==============================] - 2s 321us/step - loss: 1.2405 - acc: 0.5995 - val_loss: 1.1361 - val_acc: 0.6192\n",
      "Epoch 4/30\n",
      "4752/4752 [==============================] - 1s 290us/step - loss: 1.1677 - acc: 0.6286 - val_loss: 1.0798 - val_acc: 0.6420\n",
      "Epoch 5/30\n",
      "4752/4752 [==============================] - 1s 313us/step - loss: 1.1257 - acc: 0.6494 - val_loss: 1.0486 - val_acc: 0.6487\n",
      "Epoch 6/30\n",
      "4752/4752 [==============================] - 2s 317us/step - loss: 1.1002 - acc: 0.6568 - val_loss: 1.0296 - val_acc: 0.6529\n",
      "Epoch 7/30\n",
      "4752/4752 [==============================] - 1s 314us/step - loss: 1.0822 - acc: 0.6595 - val_loss: 1.0161 - val_acc: 0.6563\n",
      "Epoch 8/30\n",
      "4752/4752 [==============================] - 1s 300us/step - loss: 1.0690 - acc: 0.6648 - val_loss: 1.0087 - val_acc: 0.6689\n",
      "Epoch 9/30\n",
      "4752/4752 [==============================] - 1s 292us/step - loss: 1.0579 - acc: 0.6692 - val_loss: 0.9986 - val_acc: 0.6714\n",
      "Epoch 10/30\n",
      "4752/4752 [==============================] - 2s 321us/step - loss: 1.0487 - acc: 0.6684 - val_loss: 0.9940 - val_acc: 0.6681\n",
      "Epoch 11/30\n",
      "4752/4752 [==============================] - 1s 308us/step - loss: 1.0401 - acc: 0.6738 - val_loss: 0.9881 - val_acc: 0.6748\n",
      "Epoch 12/30\n",
      "4752/4752 [==============================] - 2s 318us/step - loss: 1.0328 - acc: 0.6776 - val_loss: 0.9878 - val_acc: 0.6757\n",
      "Epoch 13/30\n",
      "4752/4752 [==============================] - 1s 315us/step - loss: 1.0256 - acc: 0.6785 - val_loss: 0.9819 - val_acc: 0.6714\n",
      "Epoch 14/30\n",
      "4752/4752 [==============================] - 1s 316us/step - loss: 1.0192 - acc: 0.6829 - val_loss: 0.9799 - val_acc: 0.6706\n",
      "Epoch 15/30\n",
      "4752/4752 [==============================] - 2s 316us/step - loss: 1.0133 - acc: 0.6839 - val_loss: 0.9763 - val_acc: 0.6748\n",
      "Epoch 16/30\n",
      "4752/4752 [==============================] - 1s 300us/step - loss: 1.0076 - acc: 0.6871 - val_loss: 0.9725 - val_acc: 0.6740\n",
      "Epoch 17/30\n",
      "4752/4752 [==============================] - 1s 312us/step - loss: 1.0021 - acc: 0.6858 - val_loss: 0.9730 - val_acc: 0.6664\n",
      "Epoch 18/30\n",
      "4752/4752 [==============================] - 1s 314us/step - loss: 0.9975 - acc: 0.6867 - val_loss: 0.9677 - val_acc: 0.6748\n",
      "Epoch 19/30\n",
      "4752/4752 [==============================] - 1s 306us/step - loss: 0.9917 - acc: 0.6877 - val_loss: 0.9673 - val_acc: 0.6773\n",
      "Epoch 20/30\n",
      "4752/4752 [==============================] - 2s 317us/step - loss: 0.9879 - acc: 0.6881 - val_loss: 0.9669 - val_acc: 0.6790\n",
      "Epoch 21/30\n",
      "4752/4752 [==============================] - 2s 316us/step - loss: 0.9837 - acc: 0.6904 - val_loss: 0.9620 - val_acc: 0.6782\n",
      "Epoch 22/30\n",
      "4752/4752 [==============================] - 2s 318us/step - loss: 0.9790 - acc: 0.6923 - val_loss: 0.9624 - val_acc: 0.6731\n",
      "Epoch 23/30\n",
      "4752/4752 [==============================] - 1s 314us/step - loss: 0.9748 - acc: 0.6944 - val_loss: 0.9578 - val_acc: 0.6757\n",
      "Epoch 24/30\n",
      "4752/4752 [==============================] - 1s 310us/step - loss: 0.9714 - acc: 0.6938 - val_loss: 0.9587 - val_acc: 0.6782\n",
      "Epoch 25/30\n",
      "4752/4752 [==============================] - 1s 297us/step - loss: 0.9670 - acc: 0.6963 - val_loss: 0.9602 - val_acc: 0.6765\n",
      "Epoch 26/30\n",
      "4752/4752 [==============================] - 1s 315us/step - loss: 0.9641 - acc: 0.6989 - val_loss: 0.9554 - val_acc: 0.6799\n",
      "Epoch 27/30\n",
      "4752/4752 [==============================] - 1s 305us/step - loss: 0.9602 - acc: 0.7016 - val_loss: 0.9577 - val_acc: 0.6824\n",
      "Epoch 28/30\n",
      "4752/4752 [==============================] - 1s 313us/step - loss: 0.9569 - acc: 0.6993 - val_loss: 0.9522 - val_acc: 0.6841\n",
      "Epoch 29/30\n",
      "4752/4752 [==============================] - 2s 318us/step - loss: 0.9526 - acc: 0.7027 - val_loss: 0.9506 - val_acc: 0.6858\n",
      "Epoch 30/30\n",
      "4752/4752 [==============================] - 2s 317us/step - loss: 0.9497 - acc: 0.7048 - val_loss: 0.9550 - val_acc: 0.6841\n",
      ": 291\n",
      ": 302\n",
      ": 113\n",
      ": 87\n",
      ": 405\n",
      ": 153\n",
      "countSingleCorrect 753\n",
      "countSingleCorrect 1025\n",
      "[0.8006872852233677, 0.7052980132450332, 0.5575221238938053, 0.7586206896551724, 0.8567901234567902, 0.7254901960784313]\n",
      "Train on 4753 samples, validate on 1186 samples\n",
      "Epoch 1/30\n",
      "4753/4753 [==============================] - 2s 382us/step - loss: 1.7221 - acc: 0.3979 - val_loss: 1.4824 - val_acc: 0.5438\n",
      "Epoch 2/30\n",
      "4753/4753 [==============================] - 1s 314us/step - loss: 1.3582 - acc: 0.5603 - val_loss: 1.2811 - val_acc: 0.6155\n",
      "Epoch 3/30\n",
      "4753/4753 [==============================] - 2s 320us/step - loss: 1.2220 - acc: 0.6152 - val_loss: 1.1981 - val_acc: 0.6442\n",
      "Epoch 4/30\n",
      "4753/4753 [==============================] - 1s 313us/step - loss: 1.1583 - acc: 0.6337 - val_loss: 1.1546 - val_acc: 0.6577\n",
      "Epoch 5/30\n",
      "4753/4753 [==============================] - 2s 320us/step - loss: 1.1193 - acc: 0.6482 - val_loss: 1.1271 - val_acc: 0.6661\n",
      "Epoch 6/30\n",
      "4753/4753 [==============================] - 2s 318us/step - loss: 1.0920 - acc: 0.6560 - val_loss: 1.1086 - val_acc: 0.6695\n",
      "Epoch 7/30\n",
      "4753/4753 [==============================] - 2s 323us/step - loss: 1.0709 - acc: 0.6608 - val_loss: 1.0954 - val_acc: 0.6686\n",
      "Epoch 8/30\n",
      "4753/4753 [==============================] - 1s 307us/step - loss: 1.0557 - acc: 0.6642 - val_loss: 1.0855 - val_acc: 0.6661\n",
      "Epoch 9/30\n",
      "4753/4753 [==============================] - 1s 315us/step - loss: 1.0426 - acc: 0.6697 - val_loss: 1.0782 - val_acc: 0.6669\n",
      "Epoch 10/30\n",
      "4753/4753 [==============================] - 2s 318us/step - loss: 1.0320 - acc: 0.6730 - val_loss: 1.0709 - val_acc: 0.6627\n",
      "Epoch 11/30\n",
      "4753/4753 [==============================] - 1s 301us/step - loss: 1.0226 - acc: 0.6770 - val_loss: 1.0647 - val_acc: 0.6720\n",
      "Epoch 12/30\n",
      "4753/4753 [==============================] - 1s 314us/step - loss: 1.0140 - acc: 0.6804 - val_loss: 1.0630 - val_acc: 0.6669\n",
      "Epoch 13/30\n",
      "4753/4753 [==============================] - 2s 322us/step - loss: 1.0070 - acc: 0.6842 - val_loss: 1.0575 - val_acc: 0.6745\n",
      "Epoch 14/30\n",
      "4753/4753 [==============================] - 2s 319us/step - loss: 1.0006 - acc: 0.6842 - val_loss: 1.0545 - val_acc: 0.6788\n",
      "Epoch 15/30\n",
      "4753/4753 [==============================] - 2s 325us/step - loss: 0.9940 - acc: 0.6911 - val_loss: 1.0514 - val_acc: 0.6712\n",
      "Epoch 16/30\n",
      "4753/4753 [==============================] - 2s 324us/step - loss: 0.9887 - acc: 0.6882 - val_loss: 1.0516 - val_acc: 0.6686\n",
      "Epoch 17/30\n",
      "4753/4753 [==============================] - 1s 315us/step - loss: 0.9842 - acc: 0.6878 - val_loss: 1.0469 - val_acc: 0.6712\n",
      "Epoch 18/30\n",
      "4753/4753 [==============================] - 2s 319us/step - loss: 0.9784 - acc: 0.6903 - val_loss: 1.0459 - val_acc: 0.6712\n",
      "Epoch 19/30\n",
      "4753/4753 [==============================] - 1s 310us/step - loss: 0.9742 - acc: 0.6911 - val_loss: 1.0433 - val_acc: 0.6754\n",
      "Epoch 20/30\n",
      "4753/4753 [==============================] - 1s 315us/step - loss: 0.9698 - acc: 0.6926 - val_loss: 1.0402 - val_acc: 0.6745\n",
      "Epoch 21/30\n",
      "4753/4753 [==============================] - 2s 324us/step - loss: 0.9655 - acc: 0.6926 - val_loss: 1.0409 - val_acc: 0.6847\n",
      "Epoch 22/30\n",
      "4753/4753 [==============================] - 2s 319us/step - loss: 0.9618 - acc: 0.6956 - val_loss: 1.0405 - val_acc: 0.6745\n",
      "Epoch 23/30\n",
      "4753/4753 [==============================] - 2s 316us/step - loss: 0.9581 - acc: 0.6932 - val_loss: 1.0397 - val_acc: 0.6712\n",
      "Epoch 24/30\n",
      "4753/4753 [==============================] - 2s 319us/step - loss: 0.9541 - acc: 0.6954 - val_loss: 1.0381 - val_acc: 0.6847\n",
      "Epoch 25/30\n",
      "4753/4753 [==============================] - 2s 321us/step - loss: 0.9503 - acc: 0.6972 - val_loss: 1.0358 - val_acc: 0.6838\n",
      "Epoch 26/30\n",
      "4753/4753 [==============================] - 1s 314us/step - loss: 0.9474 - acc: 0.7015 - val_loss: 1.0366 - val_acc: 0.6779\n",
      "Epoch 27/30\n",
      "4753/4753 [==============================] - 2s 323us/step - loss: 0.9438 - acc: 0.6991 - val_loss: 1.0352 - val_acc: 0.6830\n",
      "Epoch 28/30\n",
      "4753/4753 [==============================] - 1s 307us/step - loss: 0.9400 - acc: 0.7038 - val_loss: 1.0401 - val_acc: 0.6872\n",
      "Epoch 29/30\n",
      "4753/4753 [==============================] - 2s 317us/step - loss: 0.9366 - acc: 0.7038 - val_loss: 1.0356 - val_acc: 0.6788\n",
      "Epoch 30/30\n",
      "4753/4753 [==============================] - 2s 316us/step - loss: 0.9345 - acc: 0.7046 - val_loss: 1.0367 - val_acc: 0.6838\n",
      ": 290\n",
      ": 310\n",
      ": 112\n",
      ": 95\n",
      ": 417\n",
      ": 157\n",
      "countSingleCorrect 744\n",
      "countSingleCorrect 998\n",
      "[0.7379310344827587, 0.7645161290322581, 0.6160714285714286, 0.7473684210526316, 0.8729016786570744, 0.7006369426751592]\n",
      "Train on 4753 samples, validate on 1186 samples\n",
      "Epoch 1/30\n",
      "4753/4753 [==============================] - 2s 378us/step - loss: 1.7710 - acc: 0.3575 - val_loss: 1.5173 - val_acc: 0.4798\n",
      "Epoch 2/30\n",
      "4753/4753 [==============================] - 2s 323us/step - loss: 1.3721 - acc: 0.5590 - val_loss: 1.2732 - val_acc: 0.5868\n",
      "Epoch 3/30\n",
      "4753/4753 [==============================] - 1s 314us/step - loss: 1.2071 - acc: 0.6205 - val_loss: 1.1807 - val_acc: 0.6113\n",
      "Epoch 4/30\n",
      "4753/4753 [==============================] - 2s 323us/step - loss: 1.1399 - acc: 0.6417 - val_loss: 1.1421 - val_acc: 0.6298\n",
      "Epoch 5/30\n",
      "4753/4753 [==============================] - 1s 297us/step - loss: 1.1038 - acc: 0.6560 - val_loss: 1.1207 - val_acc: 0.6391\n",
      "Epoch 6/30\n",
      "4753/4753 [==============================] - 2s 320us/step - loss: 1.0801 - acc: 0.6640 - val_loss: 1.1089 - val_acc: 0.6476\n",
      "Epoch 7/30\n",
      "4753/4753 [==============================] - 2s 321us/step - loss: 1.0628 - acc: 0.6665 - val_loss: 1.0948 - val_acc: 0.6518\n",
      "Epoch 8/30\n",
      "4753/4753 [==============================] - 2s 319us/step - loss: 1.0490 - acc: 0.6747 - val_loss: 1.0861 - val_acc: 0.6492\n",
      "Epoch 9/30\n",
      "4753/4753 [==============================] - 2s 317us/step - loss: 1.0376 - acc: 0.6760 - val_loss: 1.0803 - val_acc: 0.6594\n",
      "Epoch 10/30\n",
      "4753/4753 [==============================] - 1s 297us/step - loss: 1.0284 - acc: 0.6815 - val_loss: 1.0735 - val_acc: 0.6509\n",
      "Epoch 11/30\n",
      "4753/4753 [==============================] - 2s 321us/step - loss: 1.0202 - acc: 0.6792 - val_loss: 1.0719 - val_acc: 0.6577\n",
      "Epoch 12/30\n",
      "4753/4753 [==============================] - 2s 320us/step - loss: 1.0127 - acc: 0.6813 - val_loss: 1.0659 - val_acc: 0.6653\n",
      "Epoch 13/30\n",
      "4753/4753 [==============================] - 2s 323us/step - loss: 1.0057 - acc: 0.6869 - val_loss: 1.0602 - val_acc: 0.6518\n",
      "Epoch 14/30\n",
      "4753/4753 [==============================] - 2s 320us/step - loss: 0.9999 - acc: 0.6899 - val_loss: 1.0572 - val_acc: 0.6636\n",
      "Epoch 15/30\n",
      "4753/4753 [==============================] - 2s 322us/step - loss: 0.9941 - acc: 0.6909 - val_loss: 1.0524 - val_acc: 0.6535\n",
      "Epoch 16/30\n",
      "4753/4753 [==============================] - 2s 322us/step - loss: 0.9881 - acc: 0.6909 - val_loss: 1.0500 - val_acc: 0.6619\n",
      "Epoch 17/30\n",
      "4753/4753 [==============================] - 2s 319us/step - loss: 0.9837 - acc: 0.6947 - val_loss: 1.0485 - val_acc: 0.6619\n",
      "Epoch 18/30\n",
      "4753/4753 [==============================] - 2s 317us/step - loss: 0.9786 - acc: 0.6964 - val_loss: 1.0453 - val_acc: 0.6661\n",
      "Epoch 19/30\n",
      "4753/4753 [==============================] - 2s 318us/step - loss: 0.9743 - acc: 0.6970 - val_loss: 1.0409 - val_acc: 0.6602\n",
      "Epoch 20/30\n",
      "4753/4753 [==============================] - 1s 304us/step - loss: 0.9700 - acc: 0.6989 - val_loss: 1.0396 - val_acc: 0.6551\n",
      "Epoch 21/30\n",
      "4753/4753 [==============================] - 2s 319us/step - loss: 0.9664 - acc: 0.7000 - val_loss: 1.0367 - val_acc: 0.6610\n",
      "Epoch 22/30\n",
      "4753/4753 [==============================] - 2s 325us/step - loss: 0.9622 - acc: 0.7002 - val_loss: 1.0354 - val_acc: 0.6636\n",
      "Epoch 23/30\n",
      "4753/4753 [==============================] - 1s 315us/step - loss: 0.9582 - acc: 0.7008 - val_loss: 1.0352 - val_acc: 0.6678\n",
      "Epoch 24/30\n",
      "4753/4753 [==============================] - 2s 318us/step - loss: 0.9548 - acc: 0.7042 - val_loss: 1.0329 - val_acc: 0.6644\n",
      "Epoch 25/30\n",
      "4753/4753 [==============================] - 1s 299us/step - loss: 0.9508 - acc: 0.7067 - val_loss: 1.0304 - val_acc: 0.6644\n",
      "Epoch 26/30\n",
      "4753/4753 [==============================] - 1s 304us/step - loss: 0.9474 - acc: 0.7090 - val_loss: 1.0284 - val_acc: 0.6661\n",
      "Epoch 27/30\n",
      "4753/4753 [==============================] - 1s 300us/step - loss: 0.9443 - acc: 0.7059 - val_loss: 1.0267 - val_acc: 0.6720\n",
      "Epoch 28/30\n",
      "4753/4753 [==============================] - 1s 312us/step - loss: 0.9411 - acc: 0.7097 - val_loss: 1.0266 - val_acc: 0.6678\n",
      "Epoch 29/30\n",
      "4753/4753 [==============================] - 2s 321us/step - loss: 0.9380 - acc: 0.7120 - val_loss: 1.0250 - val_acc: 0.6754\n",
      "Epoch 30/30\n",
      "4753/4753 [==============================] - 2s 319us/step - loss: 0.9349 - acc: 0.7113 - val_loss: 1.0239 - val_acc: 0.6703\n",
      ": 290\n",
      ": 306\n",
      ": 110\n",
      ": 94\n",
      ": 412\n",
      ": 157\n",
      "countSingleCorrect 728\n",
      "countSingleCorrect 1009\n",
      "[0.7448275862068966, 0.7320261437908496, 0.5636363636363636, 0.776595744680851, 0.8616504854368932, 0.6624203821656051]\n"
     ]
    }
   ],
   "source": [
    "#generate_embeddings_10epoch_50d_humanAll    ==> 0.7325441305244833\n",
    "#generate_embeddings_10epoch_100d_humanAll_score500  ==>0.65\n",
    "#generate_embeddings_10epoch_100d_humanAll   ==> 0.7324315902459138\n",
    "#generate_embeddings_10epoch_100d_humanAllBatch2028Epoch5  ==> 0.7359638809890722\n",
    "\n",
    "re,AccuracySingle,AccuracyMultiple=train_and_evaluate_model_lstm_attention(X_train,y_train,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8459249899577841"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AccuracySingle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6941708812268571"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AccuracyMultiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=np.array(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cell_membrane': 0,\n",
       " 'Cytoplasm': 1,\n",
       " 'ER_Golgi': 2,\n",
       " 'Mitochondrion': 3,\n",
       " 'Nucleus': 4,\n",
       " 'Secreted': 5}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lableDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84376111, 0.79295405, 0.72432639, 0.80307498, 0.90384583,\n",
       "       0.75869931])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean (results,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044436113732643"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7701797689253354"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all\n",
    "np.mean (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singleplex proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4019 samples, validate on 1007 samples\n",
      "Epoch 1/20\n",
      "4019/4019 [==============================] - 1s 183us/step - loss: 1.4635 - acc: 0.5173 - val_loss: 1.1575 - val_acc: 0.6504\n",
      "Epoch 2/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.9732 - acc: 0.6870 - val_loss: 0.8381 - val_acc: 0.7448\n",
      "Epoch 3/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.7593 - acc: 0.7435 - val_loss: 0.7176 - val_acc: 0.7637\n",
      "Epoch 4/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.6707 - acc: 0.7646 - val_loss: 0.6627 - val_acc: 0.7825\n",
      "Epoch 5/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.6240 - acc: 0.7746 - val_loss: 0.6323 - val_acc: 0.7875\n",
      "Epoch 6/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.5948 - acc: 0.7845 - val_loss: 0.6103 - val_acc: 0.7905\n",
      "Epoch 7/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.5736 - acc: 0.7893 - val_loss: 0.5996 - val_acc: 0.7915\n",
      "Epoch 8/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.5571 - acc: 0.7995 - val_loss: 0.5857 - val_acc: 0.7954\n",
      "Epoch 9/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.5438 - acc: 0.8032 - val_loss: 0.5738 - val_acc: 0.8093\n",
      "Epoch 10/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.5310 - acc: 0.8089 - val_loss: 0.5634 - val_acc: 0.8123\n",
      "Epoch 11/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.5206 - acc: 0.8124 - val_loss: 0.5560 - val_acc: 0.8133\n",
      "Epoch 12/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.5102 - acc: 0.8156 - val_loss: 0.5490 - val_acc: 0.8163\n",
      "Epoch 13/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.5018 - acc: 0.8199 - val_loss: 0.5432 - val_acc: 0.8153\n",
      "Epoch 14/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.4935 - acc: 0.8253 - val_loss: 0.5383 - val_acc: 0.8163\n",
      "Epoch 15/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.4853 - acc: 0.8253 - val_loss: 0.5310 - val_acc: 0.8153\n",
      "Epoch 16/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.4778 - acc: 0.8313 - val_loss: 0.5284 - val_acc: 0.8133\n",
      "Epoch 17/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.4715 - acc: 0.8291 - val_loss: 0.5251 - val_acc: 0.8222\n",
      "Epoch 18/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.4655 - acc: 0.8325 - val_loss: 0.5210 - val_acc: 0.8123\n",
      "Epoch 19/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.4592 - acc: 0.8353 - val_loss: 0.5159 - val_acc: 0.8173\n",
      "Epoch 20/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.4541 - acc: 0.8380 - val_loss: 0.5128 - val_acc: 0.8193\n",
      ": 252\n",
      ": 153\n",
      ": 108\n",
      ": 83\n",
      ": 275\n",
      ": 136\n",
      "countSingleCorrect 825\n",
      "countSingleCorrect 1007\n",
      "[0.8888888888888888, 0.6209150326797386, 0.6944444444444444, 0.8554216867469879, 0.9054545454545454, 0.8161764705882353]\n",
      "Train on 4019 samples, validate on 1007 samples\n",
      "Epoch 1/20\n",
      "4019/4019 [==============================] - 1s 186us/step - loss: 1.4334 - acc: 0.5049 - val_loss: 1.1425 - val_acc: 0.6385\n",
      "Epoch 2/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.9565 - acc: 0.6952 - val_loss: 0.8312 - val_acc: 0.7388\n",
      "Epoch 3/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.7535 - acc: 0.7547 - val_loss: 0.7010 - val_acc: 0.7726\n",
      "Epoch 4/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.6619 - acc: 0.7751 - val_loss: 0.6418 - val_acc: 0.7805\n",
      "Epoch 5/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.6153 - acc: 0.7813 - val_loss: 0.6098 - val_acc: 0.7865\n",
      "Epoch 6/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.5861 - acc: 0.7917 - val_loss: 0.5888 - val_acc: 0.7984\n",
      "Epoch 7/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.5653 - acc: 0.8000 - val_loss: 0.5734 - val_acc: 0.8044\n",
      "Epoch 8/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.5482 - acc: 0.8027 - val_loss: 0.5627 - val_acc: 0.8054\n",
      "Epoch 9/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.5349 - acc: 0.8074 - val_loss: 0.5541 - val_acc: 0.8143\n",
      "Epoch 10/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.5223 - acc: 0.8141 - val_loss: 0.5492 - val_acc: 0.8163\n",
      "Epoch 11/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.5116 - acc: 0.8156 - val_loss: 0.5418 - val_acc: 0.8103\n",
      "Epoch 12/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.5021 - acc: 0.8189 - val_loss: 0.5359 - val_acc: 0.8153\n",
      "Epoch 13/20\n",
      "4019/4019 [==============================] - 0s 85us/step - loss: 0.4942 - acc: 0.8228 - val_loss: 0.5326 - val_acc: 0.8183\n",
      "Epoch 14/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.4859 - acc: 0.8233 - val_loss: 0.5275 - val_acc: 0.8213\n",
      "Epoch 15/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.4789 - acc: 0.8303 - val_loss: 0.5243 - val_acc: 0.8193\n",
      "Epoch 16/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.4715 - acc: 0.8306 - val_loss: 0.5204 - val_acc: 0.8203\n",
      "Epoch 17/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.4656 - acc: 0.8328 - val_loss: 0.5164 - val_acc: 0.8232\n",
      "Epoch 18/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.4589 - acc: 0.8350 - val_loss: 0.5136 - val_acc: 0.8252\n",
      "Epoch 19/20\n",
      "4019/4019 [==============================] - 0s 86us/step - loss: 0.4527 - acc: 0.8373 - val_loss: 0.5119 - val_acc: 0.8232\n",
      "Epoch 20/20\n",
      "4019/4019 [==============================] - 0s 87us/step - loss: 0.4472 - acc: 0.8383 - val_loss: 0.5080 - val_acc: 0.8292\n",
      ": 252\n",
      ": 153\n",
      ": 108\n",
      ": 83\n",
      ": 275\n",
      ": 136\n",
      "countSingleCorrect 835\n",
      "countSingleCorrect 1007\n",
      "[0.8968253968253969, 0.673202614379085, 0.7037037037037037, 0.8192771084337349, 0.9309090909090909, 0.7794117647058824]\n",
      "Train on 4020 samples, validate on 1006 samples\n",
      "Epoch 1/20\n",
      "4020/4020 [==============================] - 1s 192us/step - loss: 1.3610 - acc: 0.5211 - val_loss: 1.1004 - val_acc: 0.6282\n",
      "Epoch 2/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.9366 - acc: 0.6888 - val_loss: 0.8212 - val_acc: 0.7416\n",
      "Epoch 3/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.7420 - acc: 0.7565 - val_loss: 0.6920 - val_acc: 0.7575\n",
      "Epoch 4/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.6543 - acc: 0.7766 - val_loss: 0.6357 - val_acc: 0.7763\n",
      "Epoch 5/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.6109 - acc: 0.7878 - val_loss: 0.6080 - val_acc: 0.7793\n",
      "Epoch 6/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.5839 - acc: 0.7908 - val_loss: 0.5867 - val_acc: 0.7833\n",
      "Epoch 7/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.5644 - acc: 0.7995 - val_loss: 0.5725 - val_acc: 0.7913\n",
      "Epoch 8/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.5487 - acc: 0.8077 - val_loss: 0.5640 - val_acc: 0.7972\n",
      "Epoch 9/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.5355 - acc: 0.8107 - val_loss: 0.5536 - val_acc: 0.7972\n",
      "Epoch 10/20\n",
      "4020/4020 [==============================] - 0s 85us/step - loss: 0.5241 - acc: 0.8159 - val_loss: 0.5445 - val_acc: 0.7962\n",
      "Epoch 11/20\n",
      "4020/4020 [==============================] - 0s 85us/step - loss: 0.5146 - acc: 0.8189 - val_loss: 0.5393 - val_acc: 0.8072\n",
      "Epoch 12/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.5048 - acc: 0.8224 - val_loss: 0.5346 - val_acc: 0.8042\n",
      "Epoch 13/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.4954 - acc: 0.8254 - val_loss: 0.5330 - val_acc: 0.8052\n",
      "Epoch 14/20\n",
      "4020/4020 [==============================] - 0s 85us/step - loss: 0.4884 - acc: 0.8291 - val_loss: 0.5266 - val_acc: 0.8052\n",
      "Epoch 15/20\n",
      "4020/4020 [==============================] - 0s 85us/step - loss: 0.4810 - acc: 0.8308 - val_loss: 0.5242 - val_acc: 0.8062\n",
      "Epoch 16/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.4734 - acc: 0.8338 - val_loss: 0.5235 - val_acc: 0.8141\n",
      "Epoch 17/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.4672 - acc: 0.8343 - val_loss: 0.5200 - val_acc: 0.8121\n",
      "Epoch 18/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.4596 - acc: 0.8361 - val_loss: 0.5179 - val_acc: 0.8101\n",
      "Epoch 19/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.4550 - acc: 0.8386 - val_loss: 0.5148 - val_acc: 0.8082\n",
      "Epoch 20/20\n",
      "4020/4020 [==============================] - 0s 86us/step - loss: 0.4491 - acc: 0.8403 - val_loss: 0.5150 - val_acc: 0.8181\n",
      ": 252\n",
      ": 153\n",
      ": 108\n",
      ": 83\n",
      ": 274\n",
      ": 136\n",
      "countSingleCorrect 823\n",
      "countSingleCorrect 1006\n",
      "[0.8888888888888888, 0.5882352941176471, 0.7407407407407407, 0.891566265060241, 0.9124087591240876, 0.7720588235294118]\n",
      "Train on 4023 samples, validate on 1003 samples\n",
      "Epoch 1/20\n",
      "4023/4023 [==============================] - 1s 199us/step - loss: 1.4890 - acc: 0.4850 - val_loss: 1.1771 - val_acc: 0.6770\n",
      "Epoch 2/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.9878 - acc: 0.7131 - val_loss: 0.8154 - val_acc: 0.7527\n",
      "Epoch 3/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.7546 - acc: 0.7537 - val_loss: 0.6740 - val_acc: 0.7717\n",
      "Epoch 4/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.6631 - acc: 0.7683 - val_loss: 0.6198 - val_acc: 0.7767\n",
      "Epoch 5/20\n",
      "4023/4023 [==============================] - 0s 87us/step - loss: 0.6183 - acc: 0.7790 - val_loss: 0.5903 - val_acc: 0.7906\n",
      "Epoch 6/20\n",
      "4023/4023 [==============================] - 0s 87us/step - loss: 0.5914 - acc: 0.7887 - val_loss: 0.5700 - val_acc: 0.7926\n",
      "Epoch 7/20\n",
      "4023/4023 [==============================] - 0s 87us/step - loss: 0.5711 - acc: 0.7952 - val_loss: 0.5555 - val_acc: 0.8056\n",
      "Epoch 8/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.5552 - acc: 0.8044 - val_loss: 0.5457 - val_acc: 0.8076\n",
      "Epoch 9/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.5419 - acc: 0.8093 - val_loss: 0.5384 - val_acc: 0.8036\n",
      "Epoch 10/20\n",
      "4023/4023 [==============================] - 0s 85us/step - loss: 0.5311 - acc: 0.8143 - val_loss: 0.5302 - val_acc: 0.8096\n",
      "Epoch 11/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.5213 - acc: 0.8161 - val_loss: 0.5265 - val_acc: 0.8126\n",
      "Epoch 12/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.5116 - acc: 0.8193 - val_loss: 0.5209 - val_acc: 0.8106\n",
      "Epoch 13/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.5031 - acc: 0.8245 - val_loss: 0.5124 - val_acc: 0.8185\n",
      "Epoch 14/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.4957 - acc: 0.8277 - val_loss: 0.5099 - val_acc: 0.8136\n",
      "Epoch 15/20\n",
      "4023/4023 [==============================] - 0s 87us/step - loss: 0.4886 - acc: 0.8270 - val_loss: 0.5054 - val_acc: 0.8156\n",
      "Epoch 16/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.4823 - acc: 0.8292 - val_loss: 0.5018 - val_acc: 0.8146\n",
      "Epoch 17/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.4758 - acc: 0.8322 - val_loss: 0.5016 - val_acc: 0.8205\n",
      "Epoch 18/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.4700 - acc: 0.8295 - val_loss: 0.4985 - val_acc: 0.8166\n",
      "Epoch 19/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.4643 - acc: 0.8357 - val_loss: 0.4923 - val_acc: 0.8205\n",
      "Epoch 20/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.4588 - acc: 0.8354 - val_loss: 0.4938 - val_acc: 0.8215\n",
      ": 252\n",
      ": 152\n",
      ": 107\n",
      ": 82\n",
      ": 274\n",
      ": 136\n",
      "countSingleCorrect 824\n",
      "countSingleCorrect 1003\n",
      "[0.876984126984127, 0.5986842105263158, 0.794392523364486, 0.8170731707317073, 0.9197080291970803, 0.7941176470588235]\n",
      "Train on 4023 samples, validate on 1003 samples\n",
      "Epoch 1/20\n",
      "4023/4023 [==============================] - 1s 204us/step - loss: 1.3354 - acc: 0.5588 - val_loss: 1.0625 - val_acc: 0.6491\n",
      "Epoch 2/20\n",
      "4023/4023 [==============================] - 0s 88us/step - loss: 0.8982 - acc: 0.7199 - val_loss: 0.8240 - val_acc: 0.7248\n",
      "Epoch 3/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.7277 - acc: 0.7604 - val_loss: 0.7323 - val_acc: 0.7388A: 0s - loss: 0.7720 - acc: 0\n",
      "Epoch 4/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.6543 - acc: 0.7765 - val_loss: 0.6891 - val_acc: 0.7478\n",
      "Epoch 5/20\n",
      "4023/4023 [==============================] - 0s 87us/step - loss: 0.6156 - acc: 0.7867 - val_loss: 0.6606 - val_acc: 0.7577\n",
      "Epoch 6/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.5890 - acc: 0.7890 - val_loss: 0.6418 - val_acc: 0.7687\n",
      "Epoch 7/20\n",
      "4023/4023 [==============================] - 0s 87us/step - loss: 0.5698 - acc: 0.7949 - val_loss: 0.6293 - val_acc: 0.7717\n",
      "Epoch 8/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.5537 - acc: 0.8014 - val_loss: 0.6120 - val_acc: 0.7777\n",
      "Epoch 9/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.5402 - acc: 0.8103 - val_loss: 0.6015 - val_acc: 0.7787\n",
      "Epoch 10/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.5293 - acc: 0.8126 - val_loss: 0.5920 - val_acc: 0.7797\n",
      "Epoch 11/20\n",
      "4023/4023 [==============================] - 0s 87us/step - loss: 0.5186 - acc: 0.8175 - val_loss: 0.5849 - val_acc: 0.7876\n",
      "Epoch 12/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.5091 - acc: 0.8220 - val_loss: 0.5747 - val_acc: 0.7856\n",
      "Epoch 13/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.5000 - acc: 0.8250 - val_loss: 0.5690 - val_acc: 0.7926\n",
      "Epoch 14/20\n",
      "4023/4023 [==============================] - 0s 87us/step - loss: 0.4918 - acc: 0.8305 - val_loss: 0.5606 - val_acc: 0.7916\n",
      "Epoch 15/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.4841 - acc: 0.8345 - val_loss: 0.5562 - val_acc: 0.7956\n",
      "Epoch 16/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.4765 - acc: 0.8352 - val_loss: 0.5543 - val_acc: 0.8006\n",
      "Epoch 17/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.4711 - acc: 0.8404 - val_loss: 0.5477 - val_acc: 0.7996\n",
      "Epoch 18/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.4636 - acc: 0.8392 - val_loss: 0.5409 - val_acc: 0.8036\n",
      "Epoch 19/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.4583 - acc: 0.8429 - val_loss: 0.5399 - val_acc: 0.8026\n",
      "Epoch 20/20\n",
      "4023/4023 [==============================] - 0s 86us/step - loss: 0.4527 - acc: 0.8422 - val_loss: 0.5332 - val_acc: 0.8046\n",
      ": 252\n",
      ": 152\n",
      ": 107\n",
      ": 82\n",
      ": 274\n",
      ": 136\n",
      "countSingleCorrect 807\n",
      "countSingleCorrect 1003\n",
      "[0.8134920634920635, 0.6118421052631579, 0.7757009345794392, 0.8048780487804879, 0.948905109489051, 0.7352941176470589]\n"
     ]
    }
   ],
   "source": [
    "re,acc,_=train_and_evaluate_model_lstm_attention(X_trainSingleplex,y_trainSingleplex,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8185347721929833"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=np.array(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.873015873015873,\n",
       "  0.6209150326797386,\n",
       "  0.7222222222222222,\n",
       "  0.8433734939759037,\n",
       "  0.8945454545454545,\n",
       "  0.7941176470588235],\n",
       " [0.873015873015873,\n",
       "  0.6013071895424836,\n",
       "  0.7129629629629629,\n",
       "  0.8674698795180723,\n",
       "  0.9345454545454546,\n",
       "  0.7720588235294118],\n",
       " [0.8611111111111112,\n",
       "  0.6470588235294118,\n",
       "  0.7777777777777778,\n",
       "  0.8674698795180723,\n",
       "  0.8978102189781022,\n",
       "  0.7720588235294118],\n",
       " [0.8928571428571429,\n",
       "  0.5460526315789473,\n",
       "  0.7850467289719626,\n",
       "  0.8414634146341463,\n",
       "  0.9197080291970803,\n",
       "  0.7647058823529411],\n",
       " [0.8134920634920635,\n",
       "  0.6118421052631579,\n",
       "  0.7850467289719626,\n",
       "  0.8048780487804879,\n",
       "  0.9379562043795621,\n",
       "  0.7352941176470589]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean (results,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indipndnt Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None # Clearing the NN.\n",
    "#model = build_model()\n",
    "model = buildModelNaive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5939 samples, validate on 920 samples\n",
      "Epoch 1/30\n",
      "5939/5939 [==============================] - 1s 123us/step - loss: 1.6170 - acc: 0.4686 - val_loss: 2.3207 - val_acc: 0.4315\n",
      "Epoch 2/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 1.1076 - acc: 0.6582 - val_loss: 2.2879 - val_acc: 0.5011\n",
      "Epoch 3/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.9817 - acc: 0.7069 - val_loss: 2.3142 - val_acc: 0.5239\n",
      "Epoch 4/30\n",
      "5939/5939 [==============================] - 0s 81us/step - loss: 0.9256 - acc: 0.7227 - val_loss: 2.3470 - val_acc: 0.5141\n",
      "Epoch 5/30\n",
      "5939/5939 [==============================] - 0s 81us/step - loss: 0.8940 - acc: 0.7323 - val_loss: 2.3643 - val_acc: 0.5283\n",
      "Epoch 6/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.8711 - acc: 0.7441 - val_loss: 2.3838 - val_acc: 0.5337\n",
      "Epoch 7/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.8529 - acc: 0.7495 - val_loss: 2.3967 - val_acc: 0.5250\n",
      "Epoch 8/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.8385 - acc: 0.7545 - val_loss: 2.4058 - val_acc: 0.5380\n",
      "Epoch 9/30\n",
      "5939/5939 [==============================] - 0s 81us/step - loss: 0.8257 - acc: 0.7649 - val_loss: 2.4042 - val_acc: 0.5272\n",
      "Epoch 10/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.8151 - acc: 0.7643 - val_loss: 2.4092 - val_acc: 0.5315\n",
      "Epoch 11/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.8051 - acc: 0.7695 - val_loss: 2.4102 - val_acc: 0.5304\n",
      "Epoch 12/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7964 - acc: 0.7729 - val_loss: 2.4061 - val_acc: 0.5402\n",
      "Epoch 13/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7888 - acc: 0.7777 - val_loss: 2.4156 - val_acc: 0.5326\n",
      "Epoch 14/30\n",
      "5939/5939 [==============================] - 0s 79us/step - loss: 0.7814 - acc: 0.7798 - val_loss: 2.4145 - val_acc: 0.5522\n",
      "Epoch 15/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7739 - acc: 0.7860 - val_loss: 2.4061 - val_acc: 0.5359\n",
      "Epoch 16/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7681 - acc: 0.7850 - val_loss: 2.4043 - val_acc: 0.5587\n",
      "Epoch 17/30\n",
      "5939/5939 [==============================] - 0s 81us/step - loss: 0.7615 - acc: 0.7877 - val_loss: 2.3979 - val_acc: 0.5543\n",
      "Epoch 18/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7562 - acc: 0.7912 - val_loss: 2.3983 - val_acc: 0.5500\n",
      "Epoch 19/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7509 - acc: 0.7904 - val_loss: 2.4084 - val_acc: 0.5511\n",
      "Epoch 20/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7459 - acc: 0.7951 - val_loss: 2.4182 - val_acc: 0.5565\n",
      "Epoch 21/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7405 - acc: 0.7942 - val_loss: 2.4160 - val_acc: 0.5598\n",
      "Epoch 22/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7361 - acc: 0.7964 - val_loss: 2.4271 - val_acc: 0.5630\n",
      "Epoch 23/30\n",
      "5939/5939 [==============================] - 0s 79us/step - loss: 0.7316 - acc: 0.7983 - val_loss: 2.4130 - val_acc: 0.5641\n",
      "Epoch 24/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7272 - acc: 0.8018 - val_loss: 2.4458 - val_acc: 0.5576\n",
      "Epoch 25/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7232 - acc: 0.8023 - val_loss: 2.4379 - val_acc: 0.5489\n",
      "Epoch 26/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7188 - acc: 0.8028 - val_loss: 2.4399 - val_acc: 0.5587\n",
      "Epoch 27/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7158 - acc: 0.8055 - val_loss: 2.4357 - val_acc: 0.5554\n",
      "Epoch 28/30\n",
      "5939/5939 [==============================] - 0s 79us/step - loss: 0.7117 - acc: 0.8035 - val_loss: 2.4384 - val_acc: 0.5576\n",
      "Epoch 29/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7086 - acc: 0.8087 - val_loss: 2.4387 - val_acc: 0.5511\n",
      "Epoch 30/30\n",
      "5939/5939 [==============================] - 0s 80us/step - loss: 0.7048 - acc: 0.8074 - val_loss: 2.4509 - val_acc: 0.5565\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, validation_data=(X_test,y_test) ,epochs=30, batch_size=16,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 258\n",
      ": 296\n",
      ": 225\n",
      ": 198\n",
      ": 323\n",
      ": 112\n",
      "countSingleCorrect 341\n",
      "countSingleCorrect 541\n"
     ]
    }
   ],
   "source": [
    "\n",
    "YtestPredicted=model.predict(X_test)\n",
    "\n",
    "\n",
    "avePrec=computeAbsoluteAccuracyPerLable(y_test, YtestPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6705426356589147,\n",
       "  0.8918918918918919,\n",
       "  0.5955555555555555,\n",
       "  0.6111111111111112,\n",
       "  0.6656346749226006,\n",
       "  0.6517857142857143],\n",
       " 0.6303142329020333,\n",
       " 0.43007915567282323)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avePrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6810869305709647"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(avePrec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Multiplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 132\n",
      ": 249\n",
      ": 148\n",
      ": 83\n",
      ": 200\n",
      ": 59\n",
      "countSingleCorrect 0\n",
      "countSingleCorrect 0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-c4d6effb9646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mYtestPredicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_testMultiplx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mavePrec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomputeAbsoluteAccuracyPerLable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_testMultiplex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtestPredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-ab31b9a2e66b>\u001b[0m in \u001b[0;36mcomputeAbsoluteAccuracyPerLable\u001b[0;34m(Ytrue, Ypred)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'countSingleCorrect'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcountSingle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountSingleCorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcountSingle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountMultipleCorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcountMultiple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "YtestPredicted=model.predict(X_testMultiplx)\n",
    "\n",
    "avePrec=computeAbsoluteAccuracyPerLable(y_testMultiplex, YtestPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8333333333333334,\n",
       " 0.8755020080321285,\n",
       " 0.44594594594594594,\n",
       " 0.37349397590361444,\n",
       " 0.725,\n",
       " 0.6271186440677966]"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avePrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6467323178804698"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(avePrec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Singleplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_idx = set(multiplexProteinsIndices)  #Set is more efficient, but doesn't reorder your elements if that is desireable\n",
    "mask = np.array([(i in include_idx) for i in range(len(testProtein_weights))])\n",
    "X_testSingleplex=testProtein_weights[~mask]\n",
    "y_testSingleplex=testLablesOneHot[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 126\n",
      ": 47\n",
      ": 77\n",
      ": 115\n",
      ": 123\n",
      ": 53\n",
      "countSingleCorrect 341\n",
      "countSingleCorrect 541\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-8fca564ae540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mYtestPredicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_testSingleplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mavePrec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomputeAbsoluteAccuracyPerLable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_testSingleplex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtestPredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-ab31b9a2e66b>\u001b[0m in \u001b[0;36mcomputeAbsoluteAccuracyPerLable\u001b[0;34m(Ytrue, Ypred)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'countSingleCorrect'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcountSingle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountSingleCorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcountSingle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountMultipleCorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcountMultiple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "YtestPredicted=model.predict(X_testSingleplex)\n",
    "\n",
    "avePrec=computeAbsoluteAccuracyPerLable(y_testSingleplex, YtestPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7857142857142857,\n",
       " 0.5319148936170213,\n",
       " 0.6493506493506493,\n",
       " 0.6521739130434783,\n",
       " 0.7073170731707317,\n",
       " 0.5094339622641509]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avePrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6393174628600529"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(avePrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
