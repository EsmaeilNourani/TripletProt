{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "D1 = scipy.io.loadmat('2019/dataset/dataset_3106.mat',squeeze_me=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Y_3106', 'label_name', 'protein_list', 'sequence_3106'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MFRRKLTALDYHNPAGFNCKDETEFRNFIVWLEDQKIRHYKIEDRGNLRNIHSSDWPKFFEKYLRDVNCPFKIQDRQEAIDWLLGLAVRLEYGDNAEKYKDLVPDNSKTADNATKNAEPLINLDVNNPDFKAGVMALANLLQIQRHDDYLVMLKAIRILVQERLTQDAVAKANQTKEGLPVALDKHILGFDTGDAVLNEAAQILRLLHIEELRELQTKINEAIVAVQAIIADPKTDHRLGKVGR'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1['sequence_3106'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1['Y_3106'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1['Y_3106']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3106"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(D1['sequence_3106'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of multiplex proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.nonzero(np.sum(D1['Y_3106'],axis=1)>1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Centrosome', 'Cytoplasm', 'Cytoskeleton', 'Endosome',\n",
       "       'Endoplasmic-Reticulum', 'Extracellular', 'Golgi-Apparatus',\n",
       "       'Lysosome', 'Microsome', 'Mitochondrion', 'Nucleus', 'Peroxisome',\n",
       "       'Plasma-Membrane', 'Synapse'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1['label_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q9Y224'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1['protein_list'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q9Y224'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1['protein_list'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd= pd.DataFrame (D1['sequence_3106'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain=pd.DataFrame(D1['protein_list'],columns=['uniprot_ac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3106, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Y_3106', 'label_name', 'protein_list', 'sequence_3106'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Uniprot 2 String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #mapString2Uniprot=pd.read_csv('../uniprot2string.tsv',sep='\\t',skiprows=1,usecols=[1,2])\n",
    "# mapString2Uniprot=pd.read_csv('/home/raidmax/all_organisms.uniprot_2_string.2018.tsv',sep='\\t',skiprows=1,usecols=[1,2])\n",
    "\n",
    "\n",
    "# #mapString2Uniprot.columns=['species', 'uniprot_ac_uniprot_id', 'string_id', 'identity' ,'bit_score']\n",
    "# mapString2Uniprot.columns=['uniprot_ac_uniprot_id', 'string_id']\n",
    "\n",
    "# mapString2Uniprot['uniprot_ac'] = mapString2Uniprot.uniprot_ac_uniprot_id.str.split('|').str[0]\n",
    "\n",
    "# dfTrain=pd.merge(dfTrain,mapString2Uniprot,on=['uniprot_ac'],how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 54 out of 3106 with no string id\n",
    "# len(np.nonzero (pd.isna(dfTrain['string_id']))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pickle\n",
    "\n",
    "# with open('2019/dataset/dfTrain.pickle','wb') as handle:\n",
    "#     pickle.dump(dfTrain,handle)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('2019/dataset/dfTrain.pickle', \"rb\") as f:\n",
    "    dfTrain=pickle.load(f)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3106, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('train_test_localization.pickle', \"rb\") as f:\n",
    "#     dfTrain=pickle.load(f)\n",
    "#     dfTest=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3106"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all proteins belong to human\n",
    "len(np.nonzero (dfTrain['string_id'].str.contains('9606'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "\n",
    "# with open('../proteins_all_string_score700.pickle', \"rb\") as f:\n",
    "#     proteins=pickle.load(f)\n",
    "#proteins_all_string_score900\n",
    "#proteins_all_string\n",
    "#proteins_all_string_score750\n",
    "#proteins_all_human\n",
    "with open('../data/pickles/all_human_stringIDs_19566.pickle', \"rb\") as f:\n",
    "    proteins=pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19566"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0102 09:25:14.363333 140009304934208 deprecation_wrapper.py:119] From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#generate_embeddings_9505_1epoch_10d.h5\n",
    "#generate_embeddings_100_1epoch_10d.h5\n",
    "#generate_embeddings_100_2epoch_10d_256batch.h5\n",
    "#generate_embeddings_100_3epoch_10d_256batch\n",
    "#generate_embeddings_1epoch_20d_256batch\n",
    "#generate_embeddings_1epoch_30d_256batch.h5\n",
    "#generate_embeddings_1epoch_30d_512batchGenerator\n",
    "#generate_embeddings_1epoch_30d_256batch\n",
    "#generate_embeddings_2epoch_30d_256batch\n",
    "#generate_embeddings_3epoch_30d_512batch ==> 61.9%\n",
    "#generate_embeddings_5epoch_30d_512batch   (OK)  ==> 62%  (Ehtemalan 800)\n",
    "#generate_embeddings_1epoch_30d_1024batchGenerator_score700  ==> Acc=59%\n",
    "#generate_embeddings_10epoch_35d_2048batchScore800  ==>  ACC 63%\n",
    "#generate_embeddings_10epoch_50d_1024batchScore900\n",
    "#generate_embeddings_1epoch_30d_1024batchScore750\n",
    "#generate_embeddings_2epoch_30d_1024batchScore750\n",
    "#generate_embeddings_3epoch_30d_1024batchScore750\n",
    "#generate_embeddings_10epoch_50d_humanAll\n",
    "#embedding_modebl = load_model('../generate_embeddings_10epoch_50d_humanAll.h5',custom_objects={ 'identity_loss': identity_loss })\n",
    "embedding_modebl = load_model('../data/pickles/triplet_embeddings/Final_onlyPPI_19566_64d.h5',custom_objects={ 'identity_loss': identity_loss })\n",
    "\n",
    "\n",
    "def generate_vector(model, uid):\n",
    "\n",
    "    vector = model.get_layer('item_embedding').get_weights()[0][uid]\n",
    "\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generate_vector(embedding_modebl,383))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del embedding_modebl\n",
    "\n",
    "# #load pssm\n",
    "\n",
    "# pssm=pd.read_csv('../localization prdiction/2019/dataset/PAAC.tsv',sep='\\t')\n",
    "\n",
    "# pssm=pssm.iloc[:,1:]\n",
    "\n",
    "# pssm_norm = (pssm - pssm.mean()) / (pssm.max() - pssm.min())\n",
    "\n",
    "\n",
    "# pssm_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3106, 64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenMax=len(proteins)\n",
    "\n",
    "\n",
    "\n",
    "embedding_size=64\n",
    "\n",
    "trainProtein_weights = np.zeros((dfTrain.shape[0], embedding_size))\n",
    "\n",
    "trainProtein_weights.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3106, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_ac</th>\n",
       "      <th>uniprot_ac_uniprot_id</th>\n",
       "      <th>string_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9Y224</td>\n",
       "      <td>Q9Y224|RTRAF_HUMAN</td>\n",
       "      <td>9606.ENSP00000261700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q5JTW2</td>\n",
       "      <td>Q5JTW2|CEP78_HUMAN</td>\n",
       "      <td>9606.ENSP00000365782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q7Z460</td>\n",
       "      <td>Q7Z460|CLAP1_HUMAN</td>\n",
       "      <td>9606.ENSP00000263710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q5VT06</td>\n",
       "      <td>Q5VT06|CE350_HUMAN</td>\n",
       "      <td>9606.ENSP00000356579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5VYK3</td>\n",
       "      <td>Q5VYK3|ECM29_HUMAN</td>\n",
       "      <td>9606.ENSP00000259335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_ac uniprot_ac_uniprot_id             string_id\n",
       "0     Q9Y224    Q9Y224|RTRAF_HUMAN  9606.ENSP00000261700\n",
       "1     Q5JTW2    Q5JTW2|CEP78_HUMAN  9606.ENSP00000365782\n",
       "2     Q7Z460    Q7Z460|CLAP1_HUMAN  9606.ENSP00000263710\n",
       "3     Q5VT06    Q5VT06|CE350_HUMAN  9606.ENSP00000356579\n",
       "4     Q5VYK3    Q5VYK3|ECM29_HUMAN  9606.ENSP00000259335"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9606.ENSP00000000233'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proteins[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainProtein_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of found:  3052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3106, 64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_found=0\n",
    "for i,row in dfTrain.iterrows():\n",
    "    try:\n",
    "        protein_id=np.searchsorted(proteins,row['string_id'])\n",
    "        if protein_id != lenMax:\n",
    "            c_found += 1\n",
    "            trainProtein_weights[i]=generate_vector(embedding_modebl,protein_id)\n",
    "        else:\n",
    "            trainProtein_weights[i]=np.random.rand(embedding_size)\n",
    "    except:\n",
    "            trainProtein_weights[i]=np.random.rand(embedding_size)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "dfTrain.shape\n",
    "\n",
    "print('number of found: ',c_found)\n",
    "\n",
    "trainProtein_weights=pd.DataFrame(trainProtein_weights)\n",
    "\n",
    "trainProtein_weights.shape\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pickle\n",
    "# with open('2019/dataset/trainProtein_weights_3106D1_score900_50d_10epoch.pickle','wb') as handle:\n",
    "#     pickle.dump(trainProtein_weights,handle)\n",
    "\n",
    "# import pickle\n",
    "# #trainProtein_weights_3106D1\n",
    "# #trainProtein_weights_3106D1  Ehtemalan 5 Epoch 512 epoch\n",
    "# #trainProtein_weights_3106D1_score800_35d_10epoch\n",
    "# #trainProtein_weights_3106D1_score900_50d_10epoch\n",
    "# with open('2019/dataset/trainProtein_weights_3106D1.pickle', \"rb\") as f:\n",
    "#     trainProtein_weights=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=trainProtein_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train=pssm_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  X_train = pd.concat([trainProtein_weights, pssm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=D1['Y_3106']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3106, 14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate cross validation accuracy\n",
    "# rf = RandomForestClassifier(n_estimators=500, criterion='entropy', max_features=10, max_depth=15,\n",
    "#                             min_samples_leaf = 1, bootstrap=True, oob_score=True, n_jobs=30, random_state=0)\n",
    "# print(np.mean(cross_val_score(rf, X_train, y_train, cv=5)))\n",
    "\n",
    "# # # Fit to full training data and table feature importances\n",
    "# # rf = rf.fit(X_train, y_train)\n",
    "# # importances = rf.feature_importances_\n",
    "# # importance = pd.DataFrame(importances, index=X_train.columns, columns=[\"importance\"])\n",
    "# # # importance.sort('importance', ascending=0)\n",
    "\n",
    "# # # Print train and test accuracy\n",
    "# # y_train_pred = rf.predict(X_train)\n",
    "# # y_test_pred = rf.predict(X_test)\n",
    "# # print(\"Training Accuracy = %f\" % accuracy(y_train_pred, y_train))\n",
    "# # print(\"Test Accuracy = %f\" % accuracy(rf.predict(X_test), y_test))\n",
    "\n",
    "# # confusion_matrix(np.array(y_test), np.array(y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import average_precision_score\n",
    "# average_precision = average_precision_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import label_ranking_average_precision_score\n",
    "# y_true = np.array([[1, 0, 0], [0, 0, 1]])\n",
    "# y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])\n",
    "# label_ranking_average_precision_score(y_true, y_score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rf = RandomForestClassifier(n_estimators=500, criterion='entropy', max_features=30, max_depth=15,\n",
    "#                             min_samples_leaf = 1, bootstrap=True, oob_score=True, n_jobs=30, random_state=0)\n",
    "\n",
    "# rf = rf.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Ytest_pred = rf.predict(Xtest)\n",
    "\n",
    "#label_ranking_average_precision_score(Ytest, Ytest_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "network=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, io\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Conv1D,GlobalMaxPooling1D,MaxPooling1D,Dropout,Flatten\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras.layers  import  Conv1D,GlobalAveragePooling1D,Dense,Dropout,MaxPooling1D,GlobalMaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.expand_dims(X_train,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3106, 64, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel():\n",
    "    network = models.Sequential()\n",
    "    #network.add(Conv1D(50, 7, activation='relu', input_shape=(embedding_size+50, 1),padding='valid'))\n",
    "    network.add(Conv1D(50, 7, activation='relu', input_shape=(64, 1),padding='valid'))\n",
    "    \n",
    "    \n",
    "    network.add(layers.Dense(64, activation='relu', ))\n",
    "    network.add(layers.Dense(32, activation='relu', ))\n",
    "    network.add(layers.Flatten())    \n",
    "    network.add(layers.Dense(14, activation='sigmoid'))\n",
    "    network.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed=1311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import coverage_error\n",
    "from sklearn.metrics import label_ranking_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model_lstm_attention(W_train,Y_train):\n",
    "    prec_list=[]; reca_list=[]; fscore_list=[] ; fold=0\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=random_seed)\n",
    "    \n",
    "    all_histories=[]\n",
    "    Y = [np.argmax(y, axis=None, out=None) for y in Y_train]\n",
    "    for train_index, test_index in skf.split(W_train,Y):     \n",
    "        fold+=1\n",
    "        X_train, X_test = W_train[train_index], W_train[test_index] \n",
    "        y_train, y_test = Y_train[train_index], Y_train[test_index]\n",
    "        model = None # Clearing the NN.\n",
    "        #model = build_model()\n",
    "        model = buildModel()\n",
    "        #earlystopper = EarlyStopping(monitor='val_loss', patience=2, verbose=0)        \n",
    "\n",
    "        history=model.fit(X_train, y_train, validation_data=(X_test,y_test) ,epochs=10, batch_size=32,verbose=0)\n",
    "        \n",
    "        all_histories.append(history)\n",
    "        \n",
    "        YtestPredicted=model.predict(X_test)\n",
    "        \n",
    "        avePrec =label_ranking_average_precision_score(y_test, YtestPredicted) \n",
    "        \n",
    "        print(\"Fold {:d}: Precision:{:.2f}% \".format(fold,avePrec*100))\n",
    "        print (' coverage_error: ',coverage_error(y_test, YtestPredicted))\n",
    "        print (' label_ranking_loss: ',label_ranking_loss(y_test, YtestPredicted))\n",
    "\n",
    "        \n",
    "        prec_list.append(avePrec) \n",
    "    \n",
    "    precission=sum(prec_list)/len(prec_list)*100 \n",
    "    print(\"Final: Precision:{:.2f}% \".format(precission ))\n",
    "    #return all_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3106, 64, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Precision:76.66% \n",
      " coverage_error:  2.22488038277512\n",
      " label_ranking_loss:  0.07233087221125499\n",
      "Fold 2: Precision:76.91% \n",
      " coverage_error:  2.219551282051282\n",
      " label_ranking_loss:  0.07089011415934493\n",
      "Fold 3: Precision:76.37% \n",
      " coverage_error:  2.185483870967742\n",
      " label_ranking_loss:  0.07155378223926612\n",
      "Fold 4: Precision:76.89% \n",
      " coverage_error:  2.203225806451613\n",
      " label_ranking_loss:  0.07065615835777127\n",
      "Fold 5: Precision:77.55% \n",
      " coverage_error:  2.1707317073170733\n",
      " label_ranking_loss:  0.0717479674796748\n",
      "Final: Precision:76.88% \n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_and_evaluate_model_lstm_attention(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Precision:76.28% \n",
      " coverage_error:  2.2711323763955344\n",
      " label_ranking_loss:  0.07439959030868121\n",
      "Fold 2: Precision:76.98% \n",
      " coverage_error:  2.2099358974358974\n",
      " label_ranking_loss:  0.07021724269320423\n",
      "Fold 3: Precision:75.10% \n",
      " coverage_error:  2.225806451612903\n",
      " label_ranking_loss:  0.07391674186029025\n",
      "Fold 4: Precision:77.51% \n",
      " coverage_error:  2.220967741935484\n",
      " label_ranking_loss:  0.07190531242950599\n",
      "Fold 5: Precision:75.87% \n",
      " coverage_error:  2.245528455284553\n",
      " label_ranking_loss:  0.07740680728485606\n",
      "Final: Precision:76.35% \n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_and_evaluate_model_lstm_attention(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Precision:76.92% \n",
      " coverage_error:  2.3094098883572567\n",
      " label_ranking_loss:  0.07696378581546046\n",
      "Fold 2: Precision:76.88% \n",
      " coverage_error:  2.217948717948718\n",
      " label_ranking_loss:  0.07116094375709761\n",
      "Fold 3: Precision:76.30% \n",
      " coverage_error:  2.1903225806451614\n",
      " label_ranking_loss:  0.07068163019775923\n",
      "Fold 4: Precision:77.79% \n",
      " coverage_error:  2.2\n",
      " label_ranking_loss:  0.07133290096999774\n",
      "Fold 5: Precision:76.92% \n",
      " coverage_error:  2.183739837398374\n",
      " label_ranking_loss:  0.07367293952659806\n",
      "Final: Precision:76.96% \n"
     ]
    }
   ],
   "source": [
    "# generate_embeddings_2epoch_30d_1024batchScore750   with pssm  ==> 67.82\n",
    "#generate_embeddings_2epoch_30d_1024batchScore750    no pssm ==>62.45\n",
    "#generate_embeddings_2epoch_30d_1024batchScore750    with pssm ==>68.51\n",
    "#generate_embeddings_3epoch_30d_1024batchScore750   no pssm ==>62.38\n",
    "#generate_embeddings_3epoch_30d_1024batchScore750   with pssm ==> 68.36\n",
    "#generate_embeddings_3epoch_30d_1024batchScore750   only pssm ==> 58.75\n",
    "#generate_embeddings_10epoch_50d_humanAll   no pssm ==> 76.72\n",
    "#generate_embeddings_10epoch_50d_humanAll   with pssm ==> 77.87\n",
    "\n",
    "\n",
    "train_and_evaluate_model_lstm_attention(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
