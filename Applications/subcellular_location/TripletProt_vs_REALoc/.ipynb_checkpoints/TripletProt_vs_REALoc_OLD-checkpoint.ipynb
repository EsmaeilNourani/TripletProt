{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetFile='../../../data/REALoc/S1_dataset/5939pdataset/idLocation.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDatasetFile='../../../data/REALoc/S1_dataset/920pdataset/test_idLocation_code.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset=pd.read_csv(testDatasetFile,sep='|',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset=pd.read_csv(trainDatasetFile,sep='|',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P00505</td>\n",
       "      <td>1 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9NP58</td>\n",
       "      <td>1 3 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q96HD9</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O43687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q8N7J2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1\n",
       "0  P00505    1 4 \n",
       "1  Q9NP58  1 3 4 \n",
       "2  Q96HD9    1 2 \n",
       "3  O43687      1 \n",
       "4  Q8N7J2      1 "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O95866</td>\n",
       "      <td>Cell_membrane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q70Z44</td>\n",
       "      <td>Cell_membrane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q5I7T1</td>\n",
       "      <td>Cell_membrane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O14514</td>\n",
       "      <td>Cell_membrane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q9H159</td>\n",
       "      <td>Cell_membrane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0               1\n",
       "0  O95866  Cell_membrane \n",
       "1  Q70Z44  Cell_membrane \n",
       "2  Q5I7T1  Cell_membrane \n",
       "3  O14514  Cell_membrane \n",
       "4  Q9H159  Cell_membrane "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre process lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLables=trainDataset[[1]]\n",
    "multiplexProteinsIndicesTrain=[]\n",
    "trainLablesOneHot=np.zeros(shape=(trainLables.shape[0],6))\n",
    "\n",
    "lableDict={'Cell_membrane':0,'Cytoplasm':1,'ER_Golgi':2,'Mitochondrion':3,'Nucleus':4,'Secreted':5}\n",
    "\n",
    "for i,row in trainLables.iterrows():\n",
    "    lables=row.str.split(' ')\n",
    "    lables=list(lables)\n",
    "    lables=lables[0]\n",
    "    lables=lables[:-1]\n",
    "    if len(lables)> 1:\n",
    "        multiplexProteinsIndicesTrain.append(i)\n",
    "    for lable in lables:\n",
    "        trainLablesOneHot[i,lableDict[lable]]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5939, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLablesOneHot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLables=testDataset[[1]]\n",
    "multiplexProteinsIndices=[]\n",
    "testLablesOneHot=np.zeros(shape=(testLables.shape[0],6))\n",
    "\n",
    "\n",
    "for i,row in testLables.iterrows():\n",
    "    lables=row.str.split(' ')\n",
    "    lables=list(lables)\n",
    "    lables=lables[0]\n",
    "    lables=lables[:-1]\n",
    "    if len(lables)> 1:\n",
    "        multiplexProteinsIndices.append(i)\n",
    "    for lable in lables:\n",
    "        testLablesOneHot[i,int(lable)-1]=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testLablesOneHot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map uniprot to String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* STring IDs are required for embedding generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  utils import UniprotID_to_StringId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Train IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Matched:  140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/numpy/core/fromnumeric.py:61: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "dfTrain=trainDataset[[0]]\n",
    "\n",
    "dfTrain.columns=['uniprot_ac']\n",
    "dfTrain=UniprotID_to_StringId(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_ac</th>\n",
       "      <th>uniprot_ac_uniprot_id</th>\n",
       "      <th>string_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O95866</td>\n",
       "      <td>O95866|G6B_HUMAN</td>\n",
       "      <td>9606.ENSP00000364964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q70Z44</td>\n",
       "      <td>Q70Z44|5HT3D_HUMAN</td>\n",
       "      <td>9606.ENSP00000371929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q5I7T1</td>\n",
       "      <td>Q5I7T1|AG10B_HUMAN</td>\n",
       "      <td>9606.ENSP00000310120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O14514</td>\n",
       "      <td>O14514|AGRB1_HUMAN</td>\n",
       "      <td>9606.ENSP00000430945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q9H159</td>\n",
       "      <td>Q9H159|CAD19_HUMAN</td>\n",
       "      <td>9606.ENSP00000262150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_ac uniprot_ac_uniprot_id             string_id\n",
       "0     O95866      O95866|G6B_HUMAN  9606.ENSP00000364964\n",
       "1     Q70Z44    Q70Z44|5HT3D_HUMAN  9606.ENSP00000371929\n",
       "2     Q5I7T1    Q5I7T1|AG10B_HUMAN  9606.ENSP00000310120\n",
       "3     O14514    O14514|AGRB1_HUMAN  9606.ENSP00000430945\n",
       "4     Q9H159    Q9H159|CAD19_HUMAN  9606.ENSP00000262150"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Test IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Matched:  18\n"
     ]
    }
   ],
   "source": [
    "dfTest=testDataset[[0]]\n",
    "\n",
    "dfTest.columns=['uniprot_ac']\n",
    "\n",
    "dfTest=UniprotID_to_StringId(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load TripletProt Network and generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  utils import generate_tripletProt_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Train Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_ac</th>\n",
       "      <th>uniprot_ac_uniprot_id</th>\n",
       "      <th>string_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O95866</td>\n",
       "      <td>O95866|G6B_HUMAN</td>\n",
       "      <td>9606.ENSP00000364964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q70Z44</td>\n",
       "      <td>Q70Z44|5HT3D_HUMAN</td>\n",
       "      <td>9606.ENSP00000371929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q5I7T1</td>\n",
       "      <td>Q5I7T1|AG10B_HUMAN</td>\n",
       "      <td>9606.ENSP00000310120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O14514</td>\n",
       "      <td>O14514|AGRB1_HUMAN</td>\n",
       "      <td>9606.ENSP00000430945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q9H159</td>\n",
       "      <td>Q9H159|CAD19_HUMAN</td>\n",
       "      <td>9606.ENSP00000262150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_ac uniprot_ac_uniprot_id             string_id\n",
       "0     O95866      O95866|G6B_HUMAN  9606.ENSP00000364964\n",
       "1     Q70Z44    Q70Z44|5HT3D_HUMAN  9606.ENSP00000371929\n",
       "2     Q5I7T1    Q5I7T1|AG10B_HUMAN  9606.ENSP00000310120\n",
       "3     O14514    O14514|AGRB1_HUMAN  9606.ENSP00000430945\n",
       "4     Q9H159    Q9H159|CAD19_HUMAN  9606.ENSP00000262150"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "number of found:  5799\n"
     ]
    }
   ],
   "source": [
    "trainProtein_weights=generate_tripletProt_embeddings(dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Test Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of found:  902\n"
     ]
    }
   ],
   "source": [
    "testProtein_weights=generate_tripletProt_embeddings(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testProtein_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.array(testProtein_weights)\n",
    "X_train=np.array(trainProtein_weights)\n",
    "y_train=trainLablesOneHot\n",
    "y_test=testLablesOneHot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  computeAbsoluteAccuracyPerLable(Ytrue,Ypred):\n",
    "    countSingle=0\n",
    "    countSingleCorrect=0\n",
    "    countMultiple=0\n",
    "    countMultipleCorrect=0\n",
    "    YpredOneHot=np.zeros(shape=(Ypred.shape))\n",
    "    results=[]\n",
    "    rows=Ytrue.shape[0]\n",
    "    for i in range(rows):\n",
    "        numLables=len(np.nonzero (Ytrue[i])[0])\n",
    "        ind = np.argpartition(Ypred[i], -numLables)[-numLables:]\n",
    "        YpredOneHot[i][ind]=1\n",
    "        if numLables>1:\n",
    "            countMultiple+=1\n",
    "            if not any (np.logical_xor (YpredOneHot[i],Ytrue[i])):\n",
    "                \n",
    "                countMultipleCorrect+=1\n",
    "        else:\n",
    "            countSingle+=1\n",
    "            if  not any (np.logical_xor (YpredOneHot[i],Ytrue[i])):\n",
    "                countSingleCorrect+=1\n",
    "            \n",
    "    for i in range(6):\n",
    "        corrects=len(np.nonzero(np.logical_and(Ytrue[:,i], YpredOneHot[:,i]))[0])\n",
    "        numAllTrues=len(np.nonzero (Ytrue[:,i])[0])\n",
    "        #this class has no sample\n",
    "        if  numAllTrues==0:\n",
    "                continue\n",
    "        results.append(corrects/numAllTrues)\n",
    "    #print('countSingleCorrect',countSingleCorrect)\n",
    "    #print('countSingle',countSingle)\n",
    "    \n",
    "    return results,(countSingleCorrect/countSingle) ,(countMultipleCorrect/countMultiple)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from  model import naive_CNN_classifier\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed=1311\n",
    "embedding_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train=np.expand_dims(X_train,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(W_train,Y_train,epochs):\n",
    "    prec_list=[]; reca_list=[]; fscore_list=[] ; fold=0\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=random_seed,shuffle=True)\n",
    "    AccuracyMultiple=0\n",
    "    AccuracySingle=0\n",
    "    all_histories=[]\n",
    "    Y = [np.argmax(y, axis=None, out=None) for y in Y_train]\n",
    "    for train_index, test_index in skf.split(W_train,Y):     \n",
    "        fold+=1\n",
    "        X_train, X_test = W_train[train_index], W_train[test_index] \n",
    "        y_train, y_test = Y_train[train_index], Y_train[test_index]\n",
    "        model = None # Clearing the NN.\n",
    "        model = naive_CNN_classifier(len(lableDict),embedding_size)\n",
    "        erary_stop=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', restore_best_weights=True)\n",
    "        #history=model.fit(X_train, y_train, validation_data=(X_test,y_test) ,epochs=epochs, batch_size=8,verbose=1,callbacks=[erary_stop])\n",
    "        history=model.fit(X_train, y_train, validation_data=(X_test,y_test) ,epochs=epochs, batch_size=8,verbose=1)\n",
    "        all_histories.append(history)\n",
    "        YtestPredicted=model.predict(X_test)\n",
    "        avePrec,AS,AM=computeAbsoluteAccuracyPerLable(y_test, YtestPredicted)\n",
    "        AccuracySingle+=AS\n",
    "        AccuracyMultiple+=AM\n",
    "        prec_list.append(avePrec)\n",
    "    return prec_list,(AccuracySingle/5),(AccuracyMultiple/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 4751 samples, validate on 1188 samples\n",
      "Epoch 1/100\n",
      "4751/4751 [==============================] - 1s 212us/step - loss: 0.3184 - val_loss: 0.2606\n",
      "Epoch 2/100\n",
      "4751/4751 [==============================] - 1s 150us/step - loss: 0.2461 - val_loss: 0.2450\n",
      "Epoch 3/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2352 - val_loss: 0.2385\n",
      "Epoch 4/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2285 - val_loss: 0.2350\n",
      "Epoch 5/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2236 - val_loss: 0.2320\n",
      "Epoch 6/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2203 - val_loss: 0.2311\n",
      "Epoch 7/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2176 - val_loss: 0.2306\n",
      "Epoch 8/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2148 - val_loss: 0.2290\n",
      "Epoch 9/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2120 - val_loss: 0.2301\n",
      "Epoch 10/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2100 - val_loss: 0.2293\n",
      "Epoch 11/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2078 - val_loss: 0.2292\n",
      "Epoch 12/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2053 - val_loss: 0.2284\n",
      "Epoch 13/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2031 - val_loss: 0.2288\n",
      "Epoch 14/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2014 - val_loss: 0.2312\n",
      "Epoch 15/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2001 - val_loss: 0.2311\n",
      "Epoch 16/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.1978 - val_loss: 0.2307\n",
      "Epoch 17/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.1963 - val_loss: 0.2315\n",
      "Train on 4751 samples, validate on 1188 samples\n",
      "Epoch 1/100\n",
      "4751/4751 [==============================] - 1s 191us/step - loss: 0.3221 - val_loss: 0.2582\n",
      "Epoch 2/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2469 - val_loss: 0.2441\n",
      "Epoch 3/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2347 - val_loss: 0.2415\n",
      "Epoch 4/100\n",
      "4751/4751 [==============================] - 1s 150us/step - loss: 0.2286 - val_loss: 0.2380\n",
      "Epoch 5/100\n",
      "4751/4751 [==============================] - 1s 150us/step - loss: 0.2229 - val_loss: 0.2359\n",
      "Epoch 6/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2189 - val_loss: 0.2348\n",
      "Epoch 7/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2157 - val_loss: 0.2312\n",
      "Epoch 8/100\n",
      "4751/4751 [==============================] - 1s 150us/step - loss: 0.2121 - val_loss: 0.2323\n",
      "Epoch 9/100\n",
      "4751/4751 [==============================] - 1s 150us/step - loss: 0.2100 - val_loss: 0.2326\n",
      "Epoch 10/100\n",
      "4751/4751 [==============================] - 1s 150us/step - loss: 0.2078 - val_loss: 0.2314\n",
      "Epoch 11/100\n",
      "4751/4751 [==============================] - 1s 149us/step - loss: 0.2051 - val_loss: 0.2326\n",
      "Epoch 12/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2025 - val_loss: 0.2329\n",
      "Train on 4751 samples, validate on 1188 samples\n",
      "Epoch 1/100\n",
      "4751/4751 [==============================] - 1s 196us/step - loss: 0.3238 - val_loss: 0.2530\n",
      "Epoch 2/100\n",
      "4751/4751 [==============================] - 1s 152us/step - loss: 0.2486 - val_loss: 0.2400\n",
      "Epoch 3/100\n",
      "4751/4751 [==============================] - 1s 150us/step - loss: 0.2365 - val_loss: 0.2354\n",
      "Epoch 4/100\n",
      "4751/4751 [==============================] - 1s 150us/step - loss: 0.2295 - val_loss: 0.2320\n",
      "Epoch 5/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2241 - val_loss: 0.2292\n",
      "Epoch 6/100\n",
      "4751/4751 [==============================] - 1s 150us/step - loss: 0.2202 - val_loss: 0.2277\n",
      "Epoch 7/100\n",
      "4751/4751 [==============================] - 1s 150us/step - loss: 0.2165 - val_loss: 0.2318\n",
      "Epoch 8/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2137 - val_loss: 0.2265\n",
      "Epoch 9/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2110 - val_loss: 0.2289\n",
      "Epoch 10/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2087 - val_loss: 0.2276\n",
      "Epoch 11/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2063 - val_loss: 0.2270\n",
      "Epoch 12/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2052 - val_loss: 0.2281\n",
      "Epoch 13/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2028 - val_loss: 0.2280\n",
      "Train on 4751 samples, validate on 1188 samples\n",
      "Epoch 1/100\n",
      "4751/4751 [==============================] - 1s 204us/step - loss: 0.3145 - val_loss: 0.2521\n",
      "Epoch 2/100\n",
      "4751/4751 [==============================] - 1s 152us/step - loss: 0.2488 - val_loss: 0.2359\n",
      "Epoch 3/100\n",
      "4751/4751 [==============================] - 1s 153us/step - loss: 0.2371 - val_loss: 0.2336\n",
      "Epoch 4/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2305 - val_loss: 0.2254\n",
      "Epoch 5/100\n",
      "4751/4751 [==============================] - 1s 152us/step - loss: 0.2253 - val_loss: 0.2250\n",
      "Epoch 6/100\n",
      "4751/4751 [==============================] - 1s 152us/step - loss: 0.2221 - val_loss: 0.2218\n",
      "Epoch 7/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2188 - val_loss: 0.2224\n",
      "Epoch 8/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2160 - val_loss: 0.2229\n",
      "Epoch 9/100\n",
      "4751/4751 [==============================] - 1s 152us/step - loss: 0.2137 - val_loss: 0.2198\n",
      "Epoch 10/100\n",
      "4751/4751 [==============================] - 1s 152us/step - loss: 0.2115 - val_loss: 0.2204\n",
      "Epoch 11/100\n",
      "4751/4751 [==============================] - 1s 153us/step - loss: 0.2086 - val_loss: 0.2236\n",
      "Epoch 12/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2072 - val_loss: 0.2198\n",
      "Epoch 13/100\n",
      "4751/4751 [==============================] - 1s 152us/step - loss: 0.2049 - val_loss: 0.2212\n",
      "Epoch 14/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.2032 - val_loss: 0.2221\n",
      "Epoch 15/100\n",
      "4751/4751 [==============================] - 1s 152us/step - loss: 0.2018 - val_loss: 0.2214\n",
      "Epoch 16/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.1998 - val_loss: 0.2223\n",
      "Epoch 17/100\n",
      "4751/4751 [==============================] - 1s 151us/step - loss: 0.1986 - val_loss: 0.2228\n",
      "Train on 4752 samples, validate on 1187 samples\n",
      "Epoch 1/100\n",
      "4752/4752 [==============================] - 1s 210us/step - loss: 0.3271 - val_loss: 0.2727\n",
      "Epoch 2/100\n",
      "4752/4752 [==============================] - 1s 153us/step - loss: 0.2493 - val_loss: 0.2574\n",
      "Epoch 3/100\n",
      "4752/4752 [==============================] - 1s 153us/step - loss: 0.2363 - val_loss: 0.2536\n",
      "Epoch 4/100\n",
      "4752/4752 [==============================] - 1s 153us/step - loss: 0.2286 - val_loss: 0.2488\n",
      "Epoch 5/100\n",
      "4752/4752 [==============================] - 1s 154us/step - loss: 0.2235 - val_loss: 0.2449\n",
      "Epoch 6/100\n",
      "4752/4752 [==============================] - 1s 154us/step - loss: 0.2196 - val_loss: 0.2463\n",
      "Epoch 7/100\n",
      "4752/4752 [==============================] - 1s 153us/step - loss: 0.2156 - val_loss: 0.2449\n",
      "Epoch 8/100\n",
      "4752/4752 [==============================] - 1s 154us/step - loss: 0.2138 - val_loss: 0.2440\n",
      "Epoch 9/100\n",
      "4752/4752 [==============================] - 1s 154us/step - loss: 0.2110 - val_loss: 0.2426\n",
      "Epoch 10/100\n",
      "4752/4752 [==============================] - 1s 153us/step - loss: 0.2084 - val_loss: 0.2442\n",
      "Epoch 11/100\n",
      "4752/4752 [==============================] - 1s 154us/step - loss: 0.2064 - val_loss: 0.2441\n",
      "Epoch 12/100\n",
      "4752/4752 [==============================] - 1s 155us/step - loss: 0.2045 - val_loss: 0.2430\n",
      "Epoch 13/100\n",
      "4752/4752 [==============================] - 1s 153us/step - loss: 0.2024 - val_loss: 0.2446\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4752/4752 [==============================] - 1s 153us/step - loss: 0.2004 - val_loss: 0.2430\n"
     ]
    }
   ],
   "source": [
    "results,AccuracySingle,AccuracyMultiple=train_and_evaluate_model(X_train,y_train,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cell_membrane': 0,\n",
       " 'Cytoplasm': 1,\n",
       " 'ER_Golgi': 2,\n",
       " 'Mitochondrion': 3,\n",
       " 'Nucleus': 4,\n",
       " 'Secreted': 5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lableDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79076431, 0.73816467, 0.65686607, 0.75974755, 0.88044519,\n",
       "       0.73947941])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean (results,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average :  0.7609111992654668\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Average : ',np.mean (results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indipndnt Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None # Clearing the NN.\n",
    "\n",
    "model=naive_CNN_classifier(len(lableDict),embedding_size)\n",
    "\n",
    "#X_test=np.expand_dims(X_test,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train, y_train, validation_data=(X_test,y_test) ,epochs=30, batch_size=16,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "YtestPredicted=model.predict(X_test)\n",
    "\n",
    "results,AccuracySingle,AccuracyMultiple=computeAbsoluteAccuracyPerLable(y_test, YtestPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.748062015503876,\n",
       " 0.8141891891891891,\n",
       " 0.5555555555555556,\n",
       " 0.5757575757575758,\n",
       " 0.7058823529411765,\n",
       " 0.6517857142857143]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average :  0.6752054005388478\n"
     ]
    }
   ],
   "source": [
    "print('Average : ',np.mean (results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
