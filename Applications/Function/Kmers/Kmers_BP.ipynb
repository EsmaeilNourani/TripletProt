{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference of the dataset from DeepGO\n",
    "# ! tar -xvzf  CAFA3_training_data/data12G/data/train.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Biological Process Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBP_terms=pd.read_pickle('../../../data/DeepGo/train-bp.pkl')\n",
    "\n",
    "trainBP_terms=trainBP_terms[trainBP_terms['orgs']=='9606']\n",
    "\n",
    "testBP_terms=pd.read_pickle('../../../data/DeepGo/test-bp.pkl')\n",
    "\n",
    "testBP_terms=testBP_terms[testBP_terms['orgs']=='9606']\n",
    "\n",
    "trainBP_terms.columns=['uniprot_ac', 'gos', 'labels', 'ngrams', 'proteins', 'sequences','orgs', 'embeddings']\n",
    "\n",
    "testBP_terms.columns=['uniprot_ac', 'gos', 'labels', 'ngrams', 'proteins', 'sequences','orgs', 'embeddings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "\n",
    "data = load('../../../data/ProtVec_Kmer_baseline/k_mer_l1_norm.npz')\n",
    "\n",
    "k_mer_l1_norm=data['arr_0']\n",
    "\n",
    "embeddings=k_mer_l1_norm\n",
    "\n",
    "accessions=pd.read_csv('../../../data/ProtVec_Kmer_baseline/accessions.txt',header=None)\n",
    "\n",
    "embedding_size=embeddings.shape[1]\n",
    "trainProtein_weights = np.zeros((trainBP_terms.shape[0], embedding_size))\n",
    "testProtein_weights = np.zeros((testBP_terms.shape[0], embedding_size))\n",
    "\n",
    "for i,prot in enumerate(trainBP_terms['uniprot_ac']):  \n",
    "    trainProtein_weights[i]=embeddings[accessions.loc[accessions[0]==prot].index[0]]\n",
    "\n",
    "for i,prot in enumerate(testBP_terms['uniprot_ac']):  \n",
    "    testProtein_weights[i]=embeddings [accessions.loc[accessions[0]==prot].index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uniprot_ac', 'gos', 'labels', 'ngrams', 'proteins', 'sequences',\n",
       "       'orgs', 'embeddings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainBP_terms.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain=trainBP_terms[['labels']]\n",
    "Ytrain=Ytrain.labels.apply(pd.Series)\n",
    "Ytrain=np.array(Ytrain)\n",
    "\n",
    "X_train=trainProtein_weights\n",
    "X_train=np.array(X_train)\n",
    "X_train=np.expand_dims(X_train,axis=-1)\n",
    "\n",
    "Ytest=testBP_terms[['labels']]\n",
    "Ytest=Ytest.labels.apply(pd.Series)\n",
    "Ytest=np.array(Ytest)\n",
    "\n",
    "X_test=testProtein_weights\n",
    "X_test=np.array(X_test)\n",
    "X_test=np.expand_dims(X_test,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../utils/')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from  model import naive_CNN_classifier\n",
    "\n",
    "import keras\n",
    "\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "from numpy import arange\n",
    "\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=Ytrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=None\n",
    "model = naive_CNN_classifier(num_classes,embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train, Ytrain, validation_data=(X_test,Ytest) ,epochs=50, batch_size=16,verbose=0)\n",
    "YtestPredicted_raw=model.predict(X_test)\n",
    "avePrec =label_ranking_average_precision_score(Ytest, YtestPredicted_raw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.362192008866414"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avePrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={'treshold':[],'Average Precision':[],'F1 (micro)':[],'F1 (macro)':[],'Method':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntuadmin/anaconda37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
     ]
    }
   ],
   "source": [
    "for treshold in arange(0.05,0.55,0.05):  \n",
    "    YtestPredicted=None\n",
    "    YtestPredicted=YtestPredicted_raw.copy()\n",
    "    results['treshold'].append(treshold)\n",
    "    results['Average Precision'].append(avePrec)\n",
    "    YtestPredicted[YtestPredicted>=treshold]=1\n",
    "    YtestPredicted[YtestPredicted<treshold]=0\n",
    "    results['F1 (micro)'].append  (f1_score(Ytest, YtestPredicted, average='micro'))\n",
    "    results['F1 (macro)'].append  (f1_score(Ytest, YtestPredicted, average='macro'))\n",
    "    results['Method'].append ('Kmers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treshold</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>Method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.362192</td>\n",
       "      <td>0.269304</td>\n",
       "      <td>0.100064</td>\n",
       "      <td>Kmers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.362192</td>\n",
       "      <td>0.322130</td>\n",
       "      <td>0.094687</td>\n",
       "      <td>Kmers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.362192</td>\n",
       "      <td>0.338860</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>Kmers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.362192</td>\n",
       "      <td>0.338895</td>\n",
       "      <td>0.075888</td>\n",
       "      <td>Kmers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.362192</td>\n",
       "      <td>0.330172</td>\n",
       "      <td>0.069433</td>\n",
       "      <td>Kmers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.362192</td>\n",
       "      <td>0.315682</td>\n",
       "      <td>0.063465</td>\n",
       "      <td>Kmers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.362192</td>\n",
       "      <td>0.296381</td>\n",
       "      <td>0.057593</td>\n",
       "      <td>Kmers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.362192</td>\n",
       "      <td>0.276691</td>\n",
       "      <td>0.052838</td>\n",
       "      <td>Kmers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.362192</td>\n",
       "      <td>0.255384</td>\n",
       "      <td>0.048423</td>\n",
       "      <td>Kmers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.362192</td>\n",
       "      <td>0.233246</td>\n",
       "      <td>0.044197</td>\n",
       "      <td>Kmers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treshold  Average Precision  F1 (micro)  F1 (macro) Method\n",
       "0      0.05           0.362192    0.269304    0.100064  Kmers\n",
       "1      0.10           0.362192    0.322130    0.094687  Kmers\n",
       "2      0.15           0.362192    0.338860    0.084399  Kmers\n",
       "3      0.20           0.362192    0.338895    0.075888  Kmers\n",
       "4      0.25           0.362192    0.330172    0.069433  Kmers\n",
       "5      0.30           0.362192    0.315682    0.063465  Kmers\n",
       "6      0.35           0.362192    0.296381    0.057593  Kmers\n",
       "7      0.40           0.362192    0.276691    0.052838  Kmers\n",
       "8      0.45           0.362192    0.255384    0.048423  Kmers\n",
       "9      0.50           0.362192    0.233246    0.044197  Kmers"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('../../../data/_Outputs/Final_Kmers_BP.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
